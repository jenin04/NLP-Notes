# RoadMap

- [1. 偏差与方差](#1. 偏差与方差)
  - [1.1 定义](#1.1 定义)
  - [1.2 偏差与方差的计算公式](#1.2 偏差与方差的计算公式)
  - [1.3 作用](#1.3 作用)
  - [1.4 导致偏差和方差的原因](#1.4 导致偏差和方差的原因)
  - [1.5 偏差与方差的权衡（过拟合与模型复杂度的权衡）](#1.5 偏差与方差的权衡（过拟合与模型复杂度的权衡）)
  - [1.6 参考](#1.6 参考)
- [2. 判别式模型 VS 生成式模型](#2. 判别式模型 VS 生成式模型)
  - [2.1 两者之间的联系](#2.1 两者之间的联系)
  - [2.2 优缺点](#2.2 优缺点)
  - [2.3 常见模型](#2.3 常见模型)
- [3. 损失函数](#3. 损失函数)
  - [3.1 经验风险与结构风险](#3.1 经验风险与结构风险)
  - [3.2 常见损失函数形式](#3.2 常见损失函数形式)
    - [3.2.1 log损失函数](#3.2.1 log损失函数)
    - [3.2.2 平方损失函数](#3.2.2 平方损失函数)
    - [3.2.3 指数损失函数](#3.2.3 指数损失函数)
    - [3.2.4 合页损失函数](# 3.2.4 合页损失函数)
    - [3.2.5 0-1损失函数](# 3.2.5 0-1损失函数)
    - [3.2.6 绝对值损失函数](#3.2.6 绝对值损失函数)
  - [3.3 问题](#3.3 问题)
    - [3.3.1 为什么使用交叉熵作为损失函数，而不是均方差损失函数？](#3.3.1 为什么使用交叉熵作为损失函数，而不是均方差损失函数？)

# 1. 偏差与方差

## 1.1 定义

偏差与方差分别是用于衡量一个模型泛化误差的两个方面；从数学上来说：

- 模型的**偏差**，指的是模型预测的**期望值**与**真实值**之间的差；
- 模型的**方差**，指的是模型预测的**期望值**与**预测值**之间的差平方和；

在监督学习中，模型的**泛化误差**可分解为**偏差**、**方差**与**不能避免的误差**之和。
$$
Error(x)=Bias^2+Variance+Irreducible Error
$$

## 1.2 偏差与方差的计算公式

记在训练集 D 上学得的模型为 $f(x;D)$ 模型预测的期望为
$$
\hat{f}(x)=E_D[f(x;D)]
$$

- **偏差**（Bias）

$$
bias^2(x)=(\hat{f}(x)-y)^2
$$

​		偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；

- **方差**（Variance）

$$
var(x)=E_D[(f(x;D)-\hat{f}(x))^2]
$$

​		方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响（模型的稳定性）；

- 噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。

  “偏差-方差分解“表明模型的泛化能力是由**算法的能力**、**数据的充分性**、**任务本身的难度**共同决定的。

## 1.3 作用

偏差用于描述模型的**拟合能力**；方差用于描述模型的**稳定性**。

<img src="..\Img\Machine-Learning\01.1基础\01.png" alt="img" style="zoom:;" />

## 1.4 导致偏差和方差的原因

- **偏差**通常是由于我们对学习算法做了**错误的假设**，或者**模型的复杂度不够**；

- - 比如真实模型是一个二次函数，而我们假设模型为一次函数，这就会导致偏差的增大（欠拟合）；
  - 由偏差引起的误差通常在**训练误差**上就能体现，或者说训练误差主要是由偏差造成的

- **方差**通常是由于**模型的复杂度相对于训练集过高**导致的；

- - 比如真实模型是一个简单的二次函数，而我们假设模型是一个高次函数，这就会导致方差的增大（过拟合）；
  - 由方差引起的误差通常体现在**测试误差相对训练误差的增量**上。

**深度学习中的偏差与方差**

- 神经网络的拟合能力非常强，因此它的训练误差（偏差）通常较小；
- 但是过强的拟合能力会导致较大的方差，使模型的测试误差（泛化误差）增大；
- 因此深度学习的核心工作之一就是研究如何降低模型的泛化误差，这类方法统称为正则化方法。

## 1.5 偏差与方差的权衡（过拟合与模型复杂度的权衡）

- 给定学习任务，

- - 当训练不足时，模型的**拟合能力不够**（数据的扰动不足以使模型产生显著的变化），此时**偏差**主导模型的泛化误差；
  - 随着训练的进行，模型的拟合能力增强（模型能够学习数据发生的扰动），此时**方差**逐渐主导模型的泛化误差；
  - 当训练充足后，模型的**拟合能力过强**（数据的轻微扰动都会导致模型产生显著的变化），此时即发生**过拟合**（训练数据自身的、非全局的特征也被模型学习了）

- 偏差和方差的关系和模型容量（模型复杂度）、欠拟合和过拟合的概念紧密相联

![img](..\Img\Machine-Learning\01.1基础\02.png)

- 当模型的容量增大（x 轴）时， 偏差（用点表示）随之减小，而方差（虚线）随之增大

- 沿着 x 轴存在最佳容量，小于最佳容量会呈现欠拟合，大于最佳容量会导致过拟合。

  

## 1.6 参考

- [Understanding      the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html)
- 《深度学习》 5.4.4 权衡偏差和方差以最小化均方误差



# 2. 判别式模型 VS 生成式模型

监督学习的任务是学习一个模型，对给定的输入预测相应的输出，这个模型的一般形式为一个**决策函数**（$Y=f(X)$，直接计算$y$的值来预测$y$）或一个**条件概率分布**（后验概率$Y=f(Y|X)$）

- 决策函数：输入$X$返回$Y$；其中$Y$与一个阈值比较，然后根据比较结果判定$X$的类别
- 条件概率分布：输入$X$返回$X$属于每个类别的概率；将其中概率最大的作为$X$所属的类别

监督学习模型可分为**生成模型**与**判别模型**（《统计学习方法》 1.7 生成模型与判别模型）

- **判别模型**直接学习**决策函数**或者**条件概率分布**

- - 直观来说，判别模型学习的是类别之间的**最优分隔面**，反映的是不同类数据之间的差异

- **生成模型**学习的是**联合概率分布****P(X,Y)**，然后根据条件概率公式计算 P(Y|X)

![Discriminative  decision boundary  Generative ](..\Img\Machine-Learning\01.1基础\03.png)

## 2.1 两者之间的联系

- 由生成模型可以得到判别模型，但由判别模型得不到生成模型。

- 当存在“**隐变量**”时，只能使用**生成模型**

  > 隐变量：当我们找不到引起某一现象的原因时，就把这个在起作用，但无法确定的因素，叫“隐变量”

## 2.2 优缺点

判别模型

- 优点

- - 直接面对预测，往往学习的准确率更高
  - 由于直接学习$P(Y|X)$或$f(X)$，可以对数据进行各种程度的抽象，定义特征并使用特征，以简化学习过程
  - 相对于判别模型更加节省计算资源，需要的样本数少于生成模型。
  - 预测时，性能较生成模型好。
  - （前两条优点来源于统计学习方法，后两条来源于网络）

- 缺点

- -  捕捉不同类别特征的差异信息，不学习本身分布信息，不能反映训练数据本身的特性

生成模型

- 优点

- - 可以还原出联合概率分布$P(X,Y)$，判别方法不能。
  - 学习收敛速度更快——即当样本容量增加时，学到的模型可以更快地收敛到真实模型。
  - 当存在“隐变量”时，只能使用生成模型。

- 缺点

- - 学习和计算过程比较复杂。
  - 学习成本较高，需要更多的计算资源。
  - 需要的样本数更多，样本较少时学习效果较差。
  - 推断时性能较判别模型差。

## 2.3 常见模型

判别模型

- K 近邻、感知机（神经网络）、决策树、逻辑斯蒂回归、最大熵模型、SVM、提升方法、条件随机场

生成模型

- 朴素贝叶斯、隐马尔可夫模型、混合高斯模型、贝叶斯网络、马尔可夫随机场 



# 3. 损失函数

Loss function 是针对单一样本而言测量其惩罚值

Cost function 是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。

Object function 是有优化限制的Cost Function + 正则化项

## 3.1 经验风险与结构风险

假设有如下损失函数
$$
L(\theta)=\frac{1}{m}\sum^m_{i=1}l(\theta)+\lambda\Omega(\theta)
$$
 其中，第一项称为**经验风险** (empirical risk)，用于描述模型与训练数据的契合程度；第二项称为**结构风险** (structural risk) 或正则化项 (regularization term)，源于模型的先验概率，表述了我们希望获得何种性质的模型 (例如希望获得复杂度较小的模型)；$λ$称为正则化常数，对两者进行折中。

### 经验风险最小化

经验风险最小化只侧重训练数据集上的损失降到最低。

经验风险最小化可以看作是采用了极大似然的参数评估方法，更侧重从数据中学习模型的潜在参数，而且是只看重数据样本本身。这样在数据样本缺失的情况下，很容易管中窥豹，模型发生过拟合的状态；

MLE是经验风险最小化的例子。当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。

### 结构风险最小化

结构风险最小化是在经验风险最小化的基础上约束模型的复杂度，使其在训练数据集的损失降到最低的同时，模型不至于过于复杂，相当于在损失函数上增加了正则项，防止模型出现过拟合状态。

结构风险最小化采用了最大后验概率估计的思想来推测模型参数，不仅仅是依赖数据，还依靠模型参数的先验假设。这样在数据样本不是很充分的情况下，我们可以通过模型参数的先验假设，辅助以数据样本，做到尽可能的还原真实模型分布。

MAP是结构风险最小化的例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。 

即**结构风险最小化是在经验风险最小化的基础上增加了模型参数的先验**。

### **为什么最常假设参数的先验分布是高斯分布 (或最常使用$l2$正则化)?**

这是因为高斯分布$N(\mu;\Sigma)$是所有均值和熵存在且协方差矩阵是$\Sigma$的分布中熵最大的分布。最大熵分布是在特定约束下具有最大不确定性的分布。在没有更多信息的情况下，那些不确定的部分都是“等可能的”。在设计先验分布$p(\theta)$时，除了我们对参数的认知 (例如均值和值域) 外，我们不想引入任何其余的偏见 (bias)。因此最大熵先验 (对应$l2$正则化) 常被使用。除高斯先验外，还可以使用不提供信息的先验(uninformative prior)，其在一定范围内均匀分布，对应的损失函数中没有结构风险这一项。

 

## 3.2 常见损失函数形式

### 3.2.1 log损失函数

在逻辑回归的推导中，它假设样本服从**伯努利分布（0-1分布）**，然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：**最小化负似然函数（即max F(y, f(x)) —> min -F(y, f(x)))**。从损失函数的视角来看，它就成了**log损失函数**。

**对数损失函数的标准形式为**：
$$
L(Y,P(Y|X))=-logP(Y|X)
$$
在极大似然估计中，通常都是先取对数再求导，再找极值点，这样做是

方便计算极大似然估计。损失函数$L(Y,P(Y|X))$是指样本$X$在标签$Y$的情况下，使概率$P(Y|X)$达到最大值。（利用已知的样本分布，找到最大概率导致这种分布的参数值）

**交叉熵损失函数标准形式**：
$$
H(p,q)=-\sum^{n}_{i=1}p(x_i)log(q(x_i))
$$
其中，$p$表示样本的真实概率分布，$q$表示模型所预测的概率分布

 

### 3.2.2 平方损失函数

最小二乘法是线性回归的一种方法，它将回归的问题转化为了凸优化的问题。在线性回归中，它假设样本和噪声都服从高斯分布（中心极限定理），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘法的**基本原则**是：最优拟合曲线应该使得所有点到回归直线的距离和最小。通常用欧式距离进行距离的度量。

平方损失的损失函数（$L2$范数损失函数）为：（当样本个数为N时）
$$
L(Y,f(X))=\sum_N(Y-f(X))^2
$$
 Y−f(X)表示残差，整个式子表示的是残差平方和，我们的目标就是最小化这个目标函数值，即最小化残差的平方和。在实际应用中，我们使用均方差（MSE）作为一项衡量指标，公式如下：
$$
MSE=\frac{1}{n}\sum_{i=1}^{n}(\hat{Y}_i-Y_i)^2
$$


### 3.2.3 指数损失函数

指数损失函数的标准形式：
$$
L(Y,f(X))=e^{-Yf(X)}
$$
指数损失函数，主要应用于Boosting算法中，在Adaboost 算法中，经过m次迭代后，可以得到$f_{m(x)}$： 
$$
f_m(x)=f_{m-1}(x)+\alpha_mG_m(x)
$$
Adaboost 每次迭代时的目的都是找到最小化下列式子的参数$\alpha$和$G$ ：
$$
arg min_{\alpha,G}=\sum_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\alpha G_m(x_i))]
$$
易知，Adaboost 的目标式子就是指数损失，在给定n个样本的情况下，Adaboost 的损失函数为： 
$$
L(Y,f(X))=\frac{1}{2}\sum_{i=1}^nexp[-y_if(x_I)]
$$


###  3.2.4 合页损失函数

Hinge loss的叫法来源于其损失函数的图形，为一个折线，通用的函数表达式为：
$$
L(m_i)=max(0,1-m_i(w))
$$
表示如果被正确分类，损失是0，否则损失就是$1−m_i(w)$.

<img src="C:\Users\lznin\OneDrive\学习资料\Notes\Img\Machine-Learning\01.1基础\04.png" alt="image-20200923182610648" style="zoom: 67%;" />

Hinge loss用于最大间隔（maximum-margin）分类，其中最有代表性的就是支持向量机SVM。在支持向量机中，最初的SVM优化的函数如下：
$$
\begin{align*}
argmin \frac{1}{2}||w||^2+&C\sum_i\xi_i\\
s.t. y_i(w^Tx_i+b) {\ge}& 1-\xi_i\\
\xi_i {\ge}& 0
\end{align*}
$$
将约束项进行变形，则为： 
$$
\xi\ge1-y_iw^T	x_i
$$
则损失函数可以进一步写为：
$$
\begin{align}
J(w)&=\frac{1}{2}||w||^2+C\sum_imax(0,1-y_iw^Tx_i)\\
&=\frac{1}{2}||w||^2+C\sum_imax(0,1-m_i(w))\\
&=\frac{1}{2}||w||^2+C\sum_iL_{Hinge(m_i)}
\end{align}
$$
因此， SVM 的损失函数可以看作是 L2-norm 和 Hinge loss 之和。

###  3.2.5 0-1损失函数

$$
L(Y,f(X))=\left\{\begin{array}{}
1,y\ne f(X) &\\
0,y=f(X)&\\
\end{array}\right.
$$



### 3.2.6 绝对值损失函数

$$
L(Y,f(X))=|Y-f(X)|
$$

下面来看看几种损失函数的可视化图像，对着图看看横坐标，看看纵坐标，再看看每条线都表示什么损失函数，多看几次好好消化消化。

<img src="..\Img\Machine-Learning\01.1基础\05.png" style="zoom: 80%;" />

 

## 3.3 问题

### 3.3.1 为什么使用交叉熵作为损失函数，而不是均方差损失函数？

**若使用交叉熵作为损失函数**

神经元的输出就是 $a = σ(z)$，其中是输⼊的带权和。
$$
C=-\frac{1}{n}\sum[ylna+(1-y)ln(1-a)]
$$
其中$n$是训练数据的总数，求和是在所有的训练输⼊$x$上进⾏的，$y$是对应的⽬标输出。

- 第⼀，它是⾮负的，$C>0$。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。

- 第⼆，如果对于所有的训练输⼊$x$，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。
  - 假设在这个例⼦中， $y=0$ ⽽ $a≈0$。这是我们想到得到的结果。我们看到公式中第⼀个项就消去了，因为 $y=0$，⽽第⼆项实际上就是 $− ln(1 − a) ≈ 0$。反之， $y=1$⽽$a≈1$。所以在实际输出和⽬标输出之间的差距越⼩，最终的交叉熵的值就越低了。（这里假设输出结果不是0，就是1，实际分类也是这样的）
  - 综上所述，交叉熵是⾮负的，在神经元达到很好的正确率的时候会接近 0。这些其实就是我们想要的代价函数的特性。其实这些特性也是⼆次代价函数具备的。所以，交叉熵就是很好的选择了。

- 第三，它避免了学习速度下降的问题。

  为了弄清楚这个情况，我们来算算交叉熵函数关于权重的偏导数。我们将代⼊到 公式中应⽤两次链式法则，得到：

$$
\begin{array}{}
\frac{\partial C}{\partial w_j}&=-\frac{1}{n}\sum\frac{\partial}{\partial w_j}[ylna+(1-y)ln(1-a)]\\
&=-\frac{1}{n}\sum\frac{\partial}{\partial a}[ylna+(1-y)ln(1-a)]*\frac{\partial a}{\partial w_j}\\
&=-\frac{1}{n}\sum(\frac{y}{a}-\frac{1-y}{1-a})*\frac{\partial a}{\partial w_j}\\
&=-\frac{1}{n}\sum(\frac{y}{\xi(z)}-\frac{1-y}{1-\xi(z)})\frac{\partial \xi(z)}{\partial w_j}\\
&=-\frac{1}{n}\sum(\frac{y}{\xi(z)}-\frac{1-y}{1-\xi(z)})\xi'(z)x_j
\end{array}
$$

根据$\xi(z)=\frac{1}{1+e^{-z}}$的定义和⼀些运算，我们可以得到$\xi'(z)=\xi(z)(1-\xi(z))$。化简后可得：
$$
\frac{\partial C}{\partial w_j}=\frac{1}{n}\sum x_j(\xi(z)-y)
$$

$$
\frac{\partial C}{\partial b}=\frac{1}{n}\sum(\xi(z)-y)
$$

这个公式告诉我们权重学习的速度受到$\xi(z)-y$​，也就是输出中的误差的控制。更⼤的误差，更快的学习速度。这是我们直觉上期待的结果。特别地，这个代价函数还避免了像在⼆次代价函数中类似⽅程中$\xi'(z)$​​导致的学习缓慢。当我们使⽤交叉熵的时候，$\xi'(z)$​被约掉了，所以我们不再需要关⼼它是不是变得很⼩。这种约除就是交叉熵带来的特效。实际上，这也并不是⾮常奇迹的事情。我们在后⾯可以看到，交叉熵其实只是满⾜这种特性的⼀种选择罢了。

**若使用均方差损失函数**
$$
C=-\frac{1}{n}\sum(a-y)
$$

$$
\frac{\partial C}{\partial w_j}=\frac{1}{n}\sum(a-y)\xi'(z)x_j
$$

$$
\frac{\partial C}{\partial b}=\frac{1}{b}\sum(a-y)\xi'(z)
$$
