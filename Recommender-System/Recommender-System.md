# 1. 总体架构

## 1.1 逻辑架构

**物品信息**：商品推荐中的商品信息、视频推荐中的视频信息、新闻推荐中的新闻信息

**用户信息**：与“人”相关的信息，包括历史行为、人口属性、关系网络

**场景信息（上下文信息）**：在具体的推荐场景，用户的最终选择一般会受时间、地点、用户的状态等一系列环境信息的影响。

推荐系统处理的问题可以定义为：对于用户U，在特定场景C下，针对海量的“物品信息”，构建一个函数$f(U,I,C)$，预测用户对特定候选物品I的喜好程度，再根据喜好程度对所有候选物品进行排序，生成推荐列表的问题。

<img src="..\Img\Recommender-System\Recommender-System\21.png" alt="image-20200806094349159" style="zoom:8%;" />

## 1.2 技术架构

<img src="..\Img\Recommender-System\Recommender-System\22.png" alt="image-20200806094229623" style="zoom: 15%;" />

### 1.2.1 数据部分

推荐系统的数据部分主要负责“用户”、“物品”、“场景”的信息收集与处理。

负责数据收集与处理的三种平台按照实时性的强弱排序，依次为“客户端及服务器端实时数据处理”、“流处理平台准实时数据处理、“大数据平台离线数据处理”；同时，三种平台的海量数据处理能力则由弱到强。

加工的数据主要作用为：

- 生成推荐模型所需的样本数据，用于算法模型的训练和评估
- 生成推荐模型服务所需的“特征”，用于推荐系统的线上推断
- 生成系统监控、商业智能系统所需的统计型数据

### 1.2.2 模型部分

一般由“召回层”、“排序层”、“补充策略与算法层”组成。

- 召回层：利用高效的召回规则、算法或简单的模型，快速从海量的候选集中召回用户可能感兴趣的物品。
- 排序层：利用排序模型对初筛的候选集再进行精排序。
- 补充策略与算法层（再排序层）：可以在将推荐列表返回用户之前，为兼顾结果的“多样性”、“流行度”、“新鲜度”等指标，结合一些补充的策略和算法对推荐列表进行一定的调整，最终形成用户可见的推荐列表。

根据响应用户行为的速度不同，推荐系统可以大致分为基于**离线训练和在线训练**的推荐系统。

####  离线训练

于离线训练的推荐系统架构是最常见的一种推荐系统架构。这里的“离线”训练指的是使用历史一段时间（ 比如周或者几周 ）的数据进行训练，模型迭代的周期较长（一般 以小时为单位 ）。模型拟合的是用户的中长期兴趣。

如下图所示， 一个典型的基于离线训练的推荐系统架构由**数据上报、离线训练、在线存储、实时计算和 A/B 测试**这几个模块组成。其中，数据上报和离线训练组成了监督学习中的学习系统，而实时计算和 A/B 测试组成了预测系统。另外，除了模型之外，还有一个在线存储模块，用于存储模型和模型需要的特征信息供实时计算模块调用。图中的各个模块组成了训练和预测两条数据流，训练的数据流搜集业务的数据最后生成模型存储于在线存储模块；预测的数据流接受业务的预测请求，通过 A/B 测试模块访问实时计算模块获取预测结果。

![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-8_10-22-0.png)

1. **数据上报**：据上报模块的作用是搜集业务数据组成训练样本。一般分为收集、验证、清洗和转换几个步骤。将收集的数据转化为训练所需要的样本格式，保存到离线存储模块。

   ![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-8_10-33-46.png)

2. **离线训练**：线训练模块又细分为离线存储和离线计算。实际业务中使用的推荐系统一般都需要处理海量的用户行为数据，所以离线存储模块需要有一个分布式的文件系统或者存储平台来存储这些数据。离线计算常见的操作有：样本抽样、特征工程、模型训练、相似度计算等。

3. **在线存储**：因为线上的服务对于时延都有严格的要求。比如，某个用户打开手机 APP ，他肯定希望APP 能够快速响应，如果耗时过长，就会影响用户的体验。一般来说，这就要求推荐系统在几十毫秒以内处理完用户请求返回推荐结果，所以，针对线上的服务，需要有一个专门的在线存储模块，负责存储用于线上的模型和特征数据 。

4. **实时推荐**：实时推荐模块的功能是对来自业务的新请求进行预测。1.获取用户特征；2.调用推荐模型；3.结果排序。

   在实际应用中，因为业务的物品列表太大，如果实时计算对每个物品使用复杂的模型进行打分，就有可能耗时过长而影响用户满意度。所以，一种常见的做法是将推荐列表生成分为召回和排序两步。召回的作用是从大量的候选物品中（例如上百万）筛选出一批用户较可能喜欢的候选集 （一般是几百）。排序的作用是对召回得到的相对较小的候选集使用排序模型进行打分。更进一步，在排序得到推荐列表后，为了多样性和运营的一些考虑，还会加上第三步重排过滤，用于对精排后的推荐列表进行处理。

   ![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-8_10-40-23.png)

5. **A/B测试**：对于互联网产品来说， A/B 测试基本上是一个必备的模块，对于推荐系统来说也不例外，它可以帮助开发人员评估新算法对客户行为的影响。除了 离线的指标外，一个新的推荐算法上线之前一般都会经过 A/B 测试来测试新算法的有效性。

#### 在线训练

对于业务来说，我们希望用户对于上个广告的反馈 （喜欢或者不欢，有没有点击 ，可以很快地用于下一个广告的推荐中。这就要求我们用另一种方法来解决这个问题，这个方法就是在线训练。

基于在线训练的推荐系统架构适合于广告和电商等高维度大数据量且对实时性要求很高的场景相比较基于离线训练的推荐系统，基于在线训练的推荐系统不区分训练和测试阶段，每个回合都在学习，通过实时的反馈来调整策略。一方面，在线训练要求其样本、特征和模型的处理都是实时的，以便推荐的内容更快地反映用户实时的喜好；另一方面，因为在线训练井不需要将所有的训练数据都存储下来，所以不需要巨大的离线存储开销，使得系统具有很好的伸缩性，可以支持超大的数据量和模型。

![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-8_11-11-11.png)

1. **样本处理**：和基于离线训练的推荐系统相比，在线训练在数据上报阶段的主要不同体现在样本处理上。，对于离线训练来说，上报后的数据先是被存储到一个分布式文件系统，然后等待离线计算任务来对样本进行处理；对于在线训练来说，对样本的去重、过滤和采样等计算都需要实时进行。
2. **实时特性**：实时特征模块通过实时处理样本数据拼接训练需要的特征构造训练样本，输入流式训练模块用于更新模型。该模块的主要的功能是特征拼接和特征工程。
3. **流式训练**：流式训练模块的主要作用是使用实时训练样本来更新模型。推荐算法中增量更新部分的计算，通过流式计算的方式来进行更新。在线训练的优势之一，是可以支持模型的稀疏存储。训练方面，在线模型不一定都是从零开始训练，而是可以将离线训练得到的模型参数作为基础，在这个基础上进行增量训练。
4. **模型存储和加载**：模型一般存储在参数服务器中。模型更新后，将模型文件推送到线上存储，并由线上服务模块动态加载。



# 2. 常用特征

## 2.1 用户行为数据

用户行为数据是人与物之间的“连接”日志。

用户行为在推荐系统中一般分为**显性反馈行为**（explicit feedback）和**隐性反馈行为**（implicit feedback）

举例

| 业务场景     | 显性反馈场景             | 隐性反馈场景             |
| ------------ | ------------------------ | ------------------------ |
| 电子商务网站 | 对商品的评分             | 点击、加入购物车、购买等 |
| 视频网站     | 对视频的评分、点赞等     | 点击、播放、播放时长等   |
| 新闻类网站   | 赞、踩等行为             | 点击、评论等             |
| 音乐网站     | 对歌曲、歌手、专辑的评分 | 点击、播放、收藏等       |

对用户行为数据的使用往往涉及对业务的理解，不同的行为在抽取特征时的权重不同，一切跟业务特点强相关的用户行为需要推荐工程师自己的观察才能发现。（比如：游戏新闻中用户所爱玩的英雄等等）

当前推荐系统特征工程中，隐性反馈行为越来越重要，主要原因是显性反馈行为的收集难度过大，数据量小。在深度学习模型对数据量的要求越来越大的背景下，仅用显性反馈的数据不足以支持推荐系统训练过程的最终收敛。因此，能够反映用户行为特点的隐形反馈是目前特征挖掘的重点。

**使用方式**

- 将代表用户行为的物品id序列转换成multi-hot向量，将其作为特征向量。
- 预先训练好物品的Embedding，再通过平均或者类似DIN模型注意力机制的方法生成历史行为Embedding向量，将其作为特征向量。

## 2.2 用户关系数据

用户关系数据是人与人之间连接的记录。

用户关系可分为“**强关系**”和“**弱关系**”。

- 用户与用户之间可以通过“关注”、“好友关系”等连接建立“强关系”；
- 用户与用户之间可以通过“互相点赞”、“同处于一个社区”、“同看一部电影”建立“弱关系”。

**使用方式**

- 将用户关系作为召回层的一种物品召回方式。
- 通过用户关系建立关系图，使用Graph Embedding的方法生成用户和物品的Embedding；
- 直接利用关系数据，通过“好友”的特征为用户添加新的属性特征；
- 利用用户关系数据直接建立社会化推荐系统。

## 2.3 属性、标签类数据

属性、标签类数据是直接描述用户或物品的特征的数据。属性和标签的主体可以是用户，也可以是物品。

举例：

| 主体 | 类别                               | 来源                                                         |
| ---- | ---------------------------------- | ------------------------------------------------------------ |
| 用户 | 人口属性数据（性别、年龄、住址等） | 用户注册信息、第三方DMP（Data Management Platform，数据管理平台） |
| 用户 | 用户兴趣标签                       | 用户选择                                                     |
| 物品 | 物品标签                           | 用户或者系统管理员添加                                       |
| 物品 | 物品属性                           | 后台录入、第三方数据库。                                     |

用户属性、物品属性、标签类数据是最重要的描述型特征。例如，电商公司的商品分类体系；社交化方法由用户添加（豆瓣中“添加收藏”打标签）。

**使用方法**：

- 通过multi-hot编码的方式将其转化为特征向量。
- 一些重要的属性标签类特征也可以先转换成Embedding，再输入推荐模型。

## 2.4 内容类数据

内容类数据可以看作属性标签类特征的延伸，同样是描述物品或用户的数据，但相比标签类数据，内容类数据往往是大段的描述型文字、图片、甚至视频。

**使用方法**：

- 一般来说，内容类数据无法直接转换成推荐系统可以”消化“的特征，需要通过自然语言处理、计算机视觉等技术手段提取关键内容特征，再输入推荐系统。（比如：在图片类、视频类或带有图片的信息流推荐场景中，往往会利用计算机视觉模型进行目标检测，抽取图片特征，再把这些特征（要素）转换成标签类数据，供推荐系统使用）。

## 2.5 上下文信息

上下文信息是描述推荐行为产生的场景的信息。

举例：

最常见的上下文信息是”时间“和通过GPS获得的”地点“信息。根据推荐场景的不同，上下文信息的范围极广，包含但不限于时间、地点、季节、月份、是否节假日、天气、空气质量、社会大事件等信息。

**使用方法**：

- 尽可能地保存推荐行为发生场景的信息。（例如，在视频推荐场景中，用户倾向于在傍晚看轻松浪漫题材的电影，在深夜看悬疑惊悚题材的电影；）

## 2.6 统计类特征

统计类特征是指通过统计方法计算出的特征，例如历史CTR、历史CVR、物品热门程度、物品流行程度。

统计类特征本质上是一些粗粒度的预测指标。例如，在CTR预估问题中，完全可以将某物品的历史平均CTR当作最简单的预测模型，但该模型的预测能力很弱，因此历史平均CTR往往仅被当作复杂CTR模型的特征之一。

统计类特征往往与最后的预测目标有较强的相关性，因此是绝不应该被忽视的重要特征类别。

**使用方法**：

- 统计类特征一般是连续型特征，仅需经过标准化、归一化等处理就可以直接输入推荐系统进行训练。

## 2.7 组合类特征

组合类特征是指将不同特征进行组合后生成的新特征。

最常见的是”年龄+性别“组成的人口属性分段特征。

**使用方法**：

- 在早期推荐模型中，往往不具备特征组合的能力
- 随着深度学习的提出，组合特征不一定通过人工组合、人工筛选的方法选出，还可以交给模型进行自动处理。



# 3. 机器学习算法

## 方法概述

（1）协同过滤算法族系列：利用用户和物品之间的显式或隐式反馈信息

- ItemCF、UserCF、MF

（2）逻辑回归模型族系列：利用和融合更多用户、物品及上下文特征。

- LR

（3）因子分解机模型族：在传统逻辑回归的基础上，加入多阶特征，使模型具有了进行特征组合的能力。

- FM、FFM

（4）组合模型：融合多个模型的优点，将不同模型组合使用。此外，组合模型开始出现特征工程模型化思想。

- GBDT+LR

## 3.1 协同过滤算法

**协同过滤算法分为基于物品的协同过滤(ItemCF)和基于用户的协同过滤(UserCF)，输出结果为TOP n的推荐列表。**

### 3.1 基于用户的协同过滤(UserCF)

基于用户的协同过滤，是先计算用户 U 与其他的用户的相似度，然后取和 U 最相似的几个用户，把他们购买过的物品推荐给用户U

（1）构建用户喜爱商品的共现矩阵（行为用户，列为商品，矩阵的每个值为用户对商品的喜爱程度）。

（2）用户相似度计算。

- 倒排索引

为了计算用户相似度，我们首先要把用户购买过物品的索引数据转化成物品被用户购买过的索引数据，即物品的倒排索引：

![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-8_13-0-35.png)

建立好物品的倒排索引后，就可以根据相似度公式计算用户之间的相似度：

![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-9_8-59-5.png)

其中 N(a) 表示用户 a 购买物品的数量，N(b) 表示用户 b 购买物品的数量，N(a)∩N(b) 表示用户 a 和 b 购买相同物品的数量。有了用户的相似数据，针对用户 U 挑选 K 个最相似的用户，把他们购买过的物品中，U 未购买过的物品推荐给用户 U 即可。

- 余弦相似度

余弦相似度衡量用户**i**和用户**j**之间的向量夹角大小。显然，夹角越小，余弦相似度越大，两个用户越相似。
$$
sim(\textbf{i},\textbf{j})=cos(\textbf{i},\textbf{j})=\frac{\textbf{i}·\textbf{j}}{||\textbf{i}||·||\textbf{j}||}
$$

- 皮尔逊相关系数

$$
sim(i,j)=\frac{\sum_{p \in P}{(R_{i,p}-\bar{R}_i)(R_{j,p}-\bar{R}_j)}}{\sqrt{\sum_{p \in P}(R_{i,p}-\bar{R}_i)^2}\sqrt{\sum_{p \in P}(R_{j,p}-\bar{R}_j)^2}}
$$

其中$R_{i,p}$代表用户i对用户p的评分，$\hat{R}_i$代表用户i对所有物品的平均评分，P代表所有物品的集合。

- 基于皮尔逊相关系数引入物品平均分

$$
sim(i,j)=\frac{\sum_{p \in P}{(R_{i,p}-\bar{R_p})(R_{j,p}-\bar{R_p})}}{\sqrt{\sum_{p \in P}(R_{i,p}-\bar{R_p})^2}\sqrt{\sum_{p \in P}(R_{j,p}-\bar{R_p})^2}}
$$

其中，$\bar{R_p}$代表物品p得到所有评分的平均分。

（3）最终结果排序

假设“目标用户与其相似用户的喜好是相似的“，可根据相似用户的已有评价对目标用户的偏好进行预测。
$$
R_{u,p}=\frac{\sum_{s \in S}(w_{u,s}·R_{s,p})}{\sum_{s\in S}w_{u,s}}
$$
其中，权重$w_{u,s}$是用户u和用户s的相似度，$R_{s,p}$是用户s对物品p的评分，$R_{u,p}$是用户u对物品p的评分。

**优点**：

符合人们直觉上的“兴趣相似的朋友喜欢的物品，我也喜欢”的思想

**缺点**：

（1）在互联网应用的场景下，用户数往往大于物品数，而UserCF需要维护用户相似度矩阵以便快速找出Top n相似用户。用户相似度矩阵的存储开销非常大，而且随着业务的发展，用户数的增长会导致用户相似度矩阵的空间复杂度以$n^2$的速度快速增长，这是在线存储系统难以承受的速度。

（2）用户的历史数据向量往往非常稀疏，对于只有几次都买或者点击行为的用户来说，找到相似用户的准确度是非常低的，这导致UserCF不适用于那些正反馈获取困难的应用场景（如酒店预订、大件商品购买等低频应用）。

### 3.2 基于物品的协同过滤(ItemCF)

基于物品的协同过滤与基于用户的协同过滤（UserCF ）原理其实是类似的。基于物品的协同过滤的原理是用户 U 购买了A物品，推荐给用户U和A相似的物品B、C、D。

基于物品的协同过滤算法的核心思想：通过计算共现矩阵中物品列向量的相似度得到物品之间的相似矩阵，再找到用户的历史正反馈物品进行进一步排序和推荐。

（1）基于历史数据，构建以用户（假设用户总数为m）为行坐标，物品（物品总数为n）为列坐标的m*n维的共现矩阵。

（2）计算共现矩阵两两列向量间的相似性（相似度的计算方式与用户相似度的计算方式相同），构建n*n维的物品相似度矩阵。

（3）获得用户历史行为数据中的正反馈物品列表。

（4）利用物品相似度矩阵，针对目标用户历史行为中的正反馈物品，找出相似的Top k个物品，组成相似物品集合。

计算物品相似度的方法有以下几种：

- 基于共同喜欢物品的用户列表计算

![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-9_8-54-46.png)

在此，分母中 N(i) 是购买物品 i 的用户数，N(j) 是购买物品 j 的用户数，而分子$N(i)\cap N(j)$ 是同时购买物品i 和物品 j 的用户数。可见上述的公式的核心是计算同时购买这件商品的人数比例 。当同时购买这两个物品人数越多，他们的相似度也就越高。另外值得注意的是，在分母中我们用了物品总购买人数做惩罚，也就是说某个物品可能很热门，导致它经常会被和其他物品一起购买，所以除以它的总购买人数，来降低它和其他物品的相似分数。

- 基于余弦的相似度计算

上面的方法计算物品相似度是直接使同时购买这两个物品的人数。但是也有可能存在用户购买了但不喜欢的情况 所以如果数据集包含了具体的评分数据 我们可以进一步把用户评分引入到相似度计算中 。

![](https://latex.codecogs.com/gif.latex?w_{ij}=cos\theta=\frac{N_i*N_j}{||N_i||||N_j||}=\frac{\sum_{k=1}^{len}(n_{ki}*n_{kj})}{\sqrt{\sum_{k=1}^{len}n_{ki}^2}*\sqrt{\sum_{k=1}^{len}n_{kj}^2}})

其中$n_{ki}$是用户k对物品i的评分，如果没有评分则为0。

- 热门物品的惩罚

对于热门物品的问题，可以用如下公式解决：

![](https://gitee.com/kkweishe/images/raw/master/ML/2019-9-9_8-58-9.png)

当$\alpha\in(0,0.5)$ 时，N(i) 越小，惩罚得越厉害，从而会使热门物品相关性分数下降。

（5）对相似物品集合中的物品，利用相似度分值进行排序，生成最终的推荐列表。

如果一个物品与多个用户行为历史中的正反馈物品相似，那么该物品最终的相似度应该是多个相似度的叠加
$$
R_{u,p}=\sum_{h \in H}(w_{p,h}·R_{u,h})
$$
其中，H是目标用户的正反馈物品集合，$w_{p,h}$是物品p与物品h的物品相似度，$R_{u,h}$是用户u对物品h的已有评分。

**UserCF与ItemCF的应用场景**

- 由于UserCF基于用户相似度进行推荐，使其具备更强的社交特性，用户能够快速得知与自己兴趣相似的人最近喜欢的是什么，即使某个兴趣点以前不在自己的兴趣范围内，也有可能通过“朋友”的动态快速更新自己的推荐列表。
  - 非常适用于新闻推荐场景，因为新闻本身的兴趣点往往是分散的，想比用户对不同新闻的兴趣偏好，新闻的及时性、热点性往往是其更重要的属性，而UserCF正适用于发现热点，以及跟踪热点的趋势。

- ItemCF更适用于兴趣变化较为稳定的应用
  - 比如Amazon电商场景中，用户在一个时间段内更倾向于寻找一类商品，这时利用物品相似度为其推荐相关物品是契合用户动机的。
  - 在NetFlix的视频推荐场景中，用户观看电影、电视剧的兴趣点往往比较稳定，因此利用ItemCF推荐风格、类型相似的视频是更合理的选择。

**以上协同过滤方法的缺点**

- 系统过滤无法将两个物品相似这一信息推广到其他物品的相似性计算上，导致一个非常严重的问题——热门的物品具有很强的头部效应，容易跟大量物品产生相似性；而尾部的物品由于特征向量稀疏，很少与其他物品产生相似性，导致很少被推荐。

  -> 矩阵分解技术（用更稠密的隐向量表示用户和物品，挖掘用户和物品的隐含兴趣和隐含特征，在一定程度上弥补了协同过滤模型处理稀疏矩阵能力不足的问题）

- 协同过滤仅利用用户和物品的交互信息，无法有效地引入用户年龄、性别、商品描述、商品分类、当前时间等一系列用户特征、物品特征和上下文特征，这无疑造成了有效信息的遗漏。

  -> 引出逻辑回归模型（综合不同类型特征的机器学习模型的道路）

## 3.2 矩阵分解

### 思想

矩阵分解算法期望为每一个用户和视频生成一个隐向量，将用户和视频定位到隐向量的表示空间上，距离相近的用户和视频表明兴趣特点接近，在推荐过程中，就应该把距离相近的视频推荐给目标用户。

用户和物品的隐向量是通过分解协同过滤生成的共现矩阵得到的。矩阵分解算法将m*n维的共现矩阵$R$分解为m\*k维的用户矩阵$U$和k\*n维的物品矩阵$V$相乘的形式。其中m是用户数量，n是物品数量，k是隐向量的维度。k的大小决定了隐向量表达能力的强弱。k的取值越小，隐向量包含的信息越少，模型的泛化程度越高；反之，k的取值越大，隐向量的表达能力越强，但泛化程度相应降低。此外，k的取值还与矩阵分解的求解复杂度直接相关。

基于用户矩阵$U$和物品矩阵$V$，用户u对物品i的预估评分如下：
$$
\hat{r}_{ui}=q_i^Tp_u
$$
其中，$p_u$是用户u在用户矩阵$U$中的对应行向量，$q_i$是物品i在物品矩阵$V$中的对应列向量。

### 求解方法

#### 特征值分解

特征值分解只能作用于方阵，显然不适用于分解用户-物品矩阵。

#### 奇异值分解

假设矩阵$M$是一个m*n的矩阵，则一定存在一个分解$M=U\Sigma V^T$，其中$U$是m\*m的正交矩阵，$V$是n\*n的正交矩阵，$\Sigma$是m\*n的对角阵。

取对角阵$\Sigma$中较大的k个元素作为隐含特征，删除$\Sigma$的其他维度$U$和$V$中对应的维度，矩阵$M$被分解为$M\approx U_{m*k}\Sigma_{k*k}V_{k*n}^T$

**缺点**：

- 奇异值分解要求原始的共现矩阵是稠密的。互联网场景下大部分用户的行为历史非常少，用户-物品的共现矩阵非常稀疏，这与奇异值分解的应用条件相悖。如果应用奇异值分解，就必须对缺失的元素值进行填充。
- 传统奇异值分解的计算复杂度达到了$O(mn^2)$的级别，这对于商品数量动辄上百万、用户数量往往上千万的互联网场景来说几乎是不可接受的。

#### 梯度下降

矩阵分解的目标函数是
$$
\min_{q^*,p^*}\sum_{(u,i)\in K}(r_{ui}-q_i^Tp_u)^2
$$
其中，K是所有用户评分样本的集合。该目标函数的目的是让原始评分$r_{ui}$与用户向量和物品向量之积$q^T_ip_u$的差尽量小，这样才能最大限度地保存共现矩阵地原始信息。

为了减少过拟合现象，加入正则化项后的目标函数为
$$
\min_{q*,p*}\sum_{(u,i)\in K}(r_{ui}-q_i^Tp_u)^2+\lambda(||q_i||+||p_u||)^2
$$

#### **消除用户和物品打分的偏差**

由于不同用户的打分体系不同（比如在5分为满分的情况下，有的用户认为打3分已经是很低的分数了，而有的用户认为打1分才是比较差的评价），不同的物品的衡量标准也是有所区别（比如电子产品的平均分和日用品的平均分差异有可能比较大），为了消除用户的和物品的打分偏差，常用的做法是在矩阵分解时加入用户和物品的偏差向量，如下式所示
$$
r_{ui}=\mu+b_i+b_u+q_i^Tp_u
$$
其中，$\mu$是全局偏差常数，$b_i$是物品偏差系数，可使用物品i收到的所有评分的均值，$b_u$是用户偏差系数，可使用用户u给出的所有评分的均值。

矩阵分解的目标函数变为
$$
\min_{q^*,p^*,b^*}\sum_{(u,i)\in K}(r_{ui}-\mu-b_u-b_i-p_u^Tq_i)+\lambda(||p_u||^2+||q_i||^2+b_u^2+b_i^2)
$$
加入用户和物品的打分偏差项之后，矩阵分解得到的隐向量更能反映不同用户对不同物品的“真实”态度差异，也就更容易捕捉评价数据中有价值的信息。

#### 优点

相比协同过滤，矩阵分解有如下优点：

- 泛化能力强。在一定程度上解决了数据稀疏问题。
- 空间复杂度低。不需再存储协同过滤模型服务阶段所需的“庞大”的用户相似性或物品相似性矩阵，只需存储用户和物品隐向量。空间复杂度由$n^2$级别降低到$(n+m)·k$级别
- 更好的扩展性和灵活性。

#### 缺点

与协同过滤一样，矩阵分解同样不方便加入用户、物品和上下文相关的特征，这使得矩阵分解丧失了利用很多有效信息的机会，同时在缺乏用户历史行为时，无法进行有效的推荐。



## 3.3. Logistic Regression

在工业应用中，推荐系统通常可分为两部分——召回和排序。协同过滤属于召回的算法，从召回中得到一个比较小的推荐列表，然后经过排序之后才会输出到最终的推荐列表里，是一个有序的推荐列表。

协同过滤和矩阵分解利用用户和物品的“相似度”进行推荐，逻辑回归将推荐问题看成一个分类问题，通过预测正样本的概率对物品进行排序。逻辑回归模型将推荐问题转换成一个点击率(CTR)预估问题。

**优点**：

- 在形式上适于融合不同特征，形成较“全面”的推荐结果
- 数学含义支撑：
  - 逻辑回归作为广义线性模型的一种，它的假设是因变量y服从伯努利分布。用户是否点击广告是一个经典的掷偏心硬币问题，CTR模型的因变量显然应该服从伯努利分布。
  - 线性回归作为广义线性模型的另一个特例，其假设是因变量y服从高斯分布，这明显不是点击这类二分类问题的数学假设。
- 可解释性强：
  - 直观地讲，逻辑回归模型数学的形式是各特征的加权和，再施以sigmoid函数。在逻辑回归数学基础的支撑下，逻辑回归的简单数学形式也非常符合人类对预估过程的直觉认知。
  - 使用各特征的加权和是为了综合不同特征对CTR的影响，而不同特征的重要程度不一样，所以为不同特征指定不同的权重，代表不同特征的重要程度。最后，通过sigmoid函数，使其值能够映射到0~1区间，正好符合CTR的物理意义。
  - 算法工程师可以轻易地根据权重的不同解释哪些特征比较重要，在CTR模型的预测有偏差时定位是哪些因素影响了最后的结果。在与负责运营、产品的同事合作时，也便于给出可解释的原因，有效降低沟通成本。
- 工程化需要：
  - 在互联网公司每天动辄TB级别的数据面前，模型的训练开销和在线推断效率显得异常重要。在GPU尚未流行的2012年之前，逻辑回归模型凭借其易于并行化、模型简单、训练开销小等特点，占据着工程领域的主流。囿于工程团队的限制，即使其他复杂模型的效果有所提升，在没有明显几百逻辑回归模型之前，公司也不会贸然加大计算资源的投入，升级推荐模型或CTR模型。

**缺点**：

表达能力不强、无法进行特征交叉、特征筛选等一系列高维组合特征的操作，不可避免地造成信息的损失。

## 3.4. FM到FFM——自动特征交叉

### 3.4.1 POLY2模型——特征交叉的开始

$$
\Phi POLY2(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^nw_{h(j_1,j_2)}x_{j_1}x_{j_2}
$$

该模型对所有特征进行了两两交叉（特征$x_{j_1}$和$x_{j_2}$）,并对所有的特征组合赋予权重$w_{h(j_1,j_2)}$。

**优点**：

POLY2通过暴力组合特征的方式，在一定程度上解决了特征组合的问题。POLY2模型本质上仍是线性模型，其训练方法与逻辑回归并无区别，因此便于工程上的兼容。

**缺点**：

- 在处理互联网数据时，经常采用one-hot编码的方法处理类别型数据，致使特征向量极度稀疏，POLY2进行无选择的特征交叉——原本就非常稀疏的特征向量更加稀疏，导致大部分交叉特征缺乏有效的数据进行训练，无法收敛。
- 权重参数的数量由n直接上升到$n^2$，极大地增加了训练复杂度。

### 3.4.2 FM(Factorization Machine)模型——隐向量特征交叉

与POLY2相比，FM与其的主要区别是用两个向量的内积$(w_{j_1},w_{j_2})$取代了单一的权重系数$w_{h(j_1,j_2)}$。

FM为每个特征学习了一个隐权重向量，在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。
$$
\Phi FM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1}·w_{j_2})x_{j_1}x_{j_2}
$$
**优点**：

- FM通过引入特征隐向量的方式，直接把POLY2模型$n^2$级别的权重参数数量减少到了nk（k为隐向量维度，n>>k）。
- 隐向量的引入使FM能更好地解决数据稀疏性的问题。
- 在工程方面，FM同样可以用梯度下降法进行学习，使其不失实时性和灵活性。

### 3.4.3 FFM模型——引入特征域的概念

$$
\Phi FFM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1,f_2}·w_{j_2,f_1})x_{j_1}x_{j_2}
$$

上式是FFM的数学形式的二阶部分，其与FM的区别在于隐向量由原来的$w_{j_1}$变成了$w_{j_1,j_2}$，这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当$x_{j_1}$特征与$x_{j_2}$特征进行交叉时，$x_{j_1}$特征会从$x_{j_1}$的这一组隐向量中挑出与特征$x_{j_2}$的域$f_2$对应的隐向量$w_{j_1,f_2}$进行交叉，同理，$x_{j_2}$也会用与$x_{j_1}$的域$f_1$对应的隐向量进行交叉。

**优点**：

相比FM，FFM引入了特征域的概念，为模型引入了更多有价值的信息，使模型的表达能力更强。

**缺点**：

在FFM模型的训练过程中，需要学习n个特征在f个域上的k维隐向量，参数数量共$n·k·f$个，在训练方面，FFM的二次项并不能像FM那样简化，计算复杂度上升到$O(k·n^2)$

## 3.5 GBDT

使用梯度提升决策树(GBDT) 的方案也可以解决这个排序的问题，只是模型与 LR 不一样。GBDT作为集成模型，会使用多棵决策树，每棵树去拟合前一棵树的残差来得到很好的拟合效果。一个样本输入到一棵树中，会根据各节点的条件往下走到某个叶子节点，将此节点值置为1，其余置为0。

### 动机

FFM模型采用引入特征域的方式增强了模型的特征交叉能力，但无论如何，FFM只能做二阶的特征交叉如果继续提高特征交叉的维度，会不可避免地产生组合爆炸和计算复杂度过高的问题。寻找有效地处理高维特征组合和筛选的问题。

### GBDT+LR

Facebook提出了基于GBDT+LR组合模型的解决方法。

> He, xinran, et al. Practival lessons from predicting clicks on ads at facebook. Proceedings of the Eighth International Workshop on Data Mining for Online Advertising, ACM, 2014

大致想法是利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当作LR模型输入。

需要强调的是用GBDT构建特征工程，利用LR预估CTR这两步是独立训练的，所以不存在如何将LR的梯度回传到GBDT这类复杂的问题。

GBDT是由多棵回归树组成的树林，后一棵树以前面树林的结果与真实结果的残差为拟合目标，每棵树生成的过程是一棵标准的回归树生成过程，因此回归树中每个节点的分裂是一个自然的特征选择的过程，而多层节点的结构则对特征进行了有效地自动组合，也就非常高效地解决了过去棘手的特征选择和特征组合问题。

#### GBDT进行特征转换

一个训练样本在输入GBDT的某一子树后，会根据每个节点的规则最终落入某一叶子节点，把该叶子节点置为1，其他叶子节点置为0，所有叶子节点组成的向量即形成了该棵树的特征向量，把GBDT所有子树的特征向量连接起来，即形成了后续LR模型输入的离散型特征向量。

**优点**：

- 决策树的深度决定了特征交叉的阶数。如果决策树的深度为4，则通过3次节点分裂，最终的叶节点实际上是进行三层特征组合后的结果，这种特征组合能力显然是FM系的模型不具备的。

**缺点**:

- GBDT容易产生过拟合
- GBDT的特征转换方式实际上丢失了大量特征的数值信息，因此不能简单地说GBDT的特征交叉能力强，效果就比FFM好，在模型的选择和调试上，永远都是多种因素综合作用的结果。

GBDT+LR模型相对于只用GBDT会有略微的提升，更大的好处是防止GBDT过拟合。升级为GBDT+LR后，线上效果提升了约5%，并且因为省去了对新特征进行人工转换的步骤，增加特征的迭代测试也更容易了。

#### 意义

在GBDT+LR组合模型出现之前，特征工程的主要解决方法有两个：

- 一是人工的或半人工的特征组合和特征筛选；(弊端：对算法工程师的经验和精力投入要求较高)
- 二是通过改造目标函数，改进模型结构，增加特征交叉项的方式增强特征组合能力；（弊端：要求从根本上改变模型结构，对模型设计能力的要求较高）

GBDT+LR组合模型的提出，意味着特征工程可以完全交由一个独立的模型来完成，模型的输入可以是原始的特征向量，不必在特征工程上投入过多的人工筛选和模型设计的精力，实现真正的端到端训练。

广义上讲，深度学习通过各类网络结构、Embedding层等方法完成特征工程自动化，都是GBDT+LR开启的**特征工程模型化**这一趋势。

### GBDT+FM

GBDT是不支持高维稀疏特征的，如果将高维特征加到LR中，一方面需要人工组合高维特征，另一方面模型维度和计算复杂度会是$O(N^2)$级别的增长。所以设计了GBDT+FM的模型如图所示，采用Factorization Machines模型替换LR。

![](https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase6415480884894524319.png)

Factorization Machines（FM）模型如下所示：

![](https://latex.codecogs.com/gif.latex?\hat{y}(x)=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j=i+1}^nx_ix_j)

具有以下几个优点
①前两项为一个线性模型，相当于LR模型的作用
②第三项为一个二次交叉项，能够自动对特征进行交叉组合
③通过增加隐向量，模型训练和预测的计算复杂度降为了O(N)
④支持稀疏特征。

几个优点使得GBDT+FM具有了良好的稀疏特征支持，FM使用GBDT的叶子结点和稀疏特征（内容特征）作为输入，模型结构示意图如下，GBDT+FM模型上线后相比GBDT+LR在各项指标的效果提升在4%~6%之间。

### DNN+GBDT+FM

GBDT+FM模型，对embedding等具有结构信息的深度特征利用不充分，而深度学习（Deep Neural Network）能够对嵌入式（embedding）特征和普通稠密特征进行学习，抽取出深层信息，提高模型的准确性，并已经成功应用到众多机器学习领域。因此我们将DNN引入到排序模型中，提高排序整体质量。

DNN+GBDT+FM的ensemble模型架构如图所示，FM层作为模型的最后一层，即融合层，其输入由三部分组成：DNN的最后一层隐藏层、GBDT的输出叶子节点、高维稀疏特征。DNN+GBDT+FM的ensemble模型架构介绍如下所示，该模型上线后相对于GBDT+FM有4%的效果提升。

![](https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase64154808867345373562.png)

使用分布式的TensorFlow进行训练，使用基于TensorFlow Serving的微服务进行在线预测，DNN+GBDT+FM的ensemble模型使用的是Adam优化器。Adam结合了The Adaptive Gradient Algorithm（AdaGrad）和Root Mean Square Propagation（RMSProp）算法。具有更优的收敛速率，每个变量有独自的下降步长，整体下降步长会根据当前梯度进行调节，能够适应带噪音的数据。实验测试了多种优化器，Adam的效果是最优的。



# 4. 深度学习算法

## 改进方向概述

（1）改变神经网络的复杂程度：主要进化方式在于——增加了深度神经网络的层数和结构复杂度。

- AutoRec、Deep Crossing

（2）改变特征交叉方式：丰富深度学习网络中特征交叉的方式。

- NeuralCF、PNN

（3）组合模型：组合两种不同特点、优势互补的深度学习网络，提升模型的综合能力。

- Wide&Deep、Deep&Cross、DeepFM

（4）FM模型的深度学习演化版本

- FNN、DeepFM、NFM、AFM

以上几种都是修改特征交互操作的思路，但**特征工程**的思路走到这里几乎已经穷尽了可能的尝试，模型进一步提升的空间非常小，这也是这类模型的局限性。

从这之后，越来越多的深度学习推荐模型开始探索更多“**结构**”上的尝试。

（5）注意力机制与推荐模型的结合：主要是讲注意力机制应用于深度学习推荐模型中。

- AFM、DIN

（6）序列模型与推荐模型的结合：使用序列模型模拟用户行为或用户兴趣的演化趋势。

- DIEN

（7）强化学习与推荐模型的结合：将强化学习应用于推荐领域，强调模型的在线学习和实时更新。

- DRN

## 4.1 AutoRec——单隐层神经网络模型

> Sedhain, Suvash, et al. Autorec: Autoencoders meet collaborative filtering. Proceedings of the 24th International Conference on World Wide Web. ACM, 2015.

AutoRec将自编码器的思想和协同过滤结合，提出了一种单隐层神经网络推荐模型。

### 基本思想

利用协同过滤中的共现矩阵，完成物品向量或者用户向量的自编码。再利用自编码的结果得到用户对物品的预估评分，进而进行推荐排序。

### 模型结构

假设有m个用户，n个物品，用户会对n个物品中的一个或几个进行评分，未评分的物品分值可用默认值或平均分值表示，则所有m个用户对物品的评分可形成一个$m \times n$维的评分矩阵，也就是协同过滤中的共现矩阵。

对一个物品i来说，所有m个用户对它的评分可形成一个m维向量$r^{(i)}=(R_{1i},...,R_{mi})$，AutoRec要解决的问题是构建一个重建函数$h(\textbf{r};\theta)$，使所有该重建函数生成的评分向量与原评分向量的平方残差和最小。

网络的输入层是物品的评分向量$\textbf{r}$，输出层是一个多分类层。

<img src="..\Img\Recommender-System\Recommender-System\01.png" alt="image-20200801164830787" style="zoom:50%;" />

该模型结构代表的重建函数的具体形式如下：
$$
h(\textbf{r};\theta)=f(\textbf{W}·g(\textbf{V}_r, \mu)+b)
$$
其中，$f(·)$，$g(·)$分别为输出层神经元和隐藏层神经元的激活函数。

为了防止重构函数过拟合，加入L2正则化项后，AutoRec目标函数的具体形式如下：
$$
\min_\theta\sum_{i=1}^n||\textbf{r}^{(i)}-h(\textbf{r}^{(i)};\theta)||^2+\frac{\lambda}{2}·(||\textbf{W}||^2_F+||\textbf{V}||^2_F)
$$
模型的训练利用梯度反向传播即可完成。

### 基于AutoRec模型的推荐过程

在得到AutoRec模型的重建函数后，还要经过评分预估和排序的过程才能得到最终的推荐列表。

当输入物品i的评分向量为$r^{(i)}$时，模型的输出向量$h(r^{(i)};\theta)$就是所有用户对物品i的评分预测，其中第u维就是用户u对物品i的预测$\hat{R}_{ui}$。

通过遍历输入物品向量就可以得到用户u对所有物品的评分预测，进而根据评分预测排序得到推荐列表。

类似协同过滤，AutoRec可以分为基于物品的AutoRec和基于用户的AutoRec。

- I-AutoRec(Item based AutoRec)：输入向量是物品的评分向量。
- U-AutoRec(User based AutoRec)：输入向量是用户的评分向量。

两者对比：

- U-AutoRec相比I-AutoRec的优势在于仅需输入一次目标用户的用户向量，就可以重建用户对所有物品的评分向量。
- U-AutoRec相比I-AutoRec的劣势在于用户向量的稀疏性可能会影响模型效果。

### AutoRec评价

**优点**：

- 模型使用一个单隐层的AutoEncoder泛化用户或物品评分，使模型具有一定的泛化和表达能力。

**缺点**：

- 模型结构简单，存在一定的表达能力不足的问题。



## 4.2 Deep Crossing

微软于2016年提出的Deep Crossing模型

> Shan， Ying， et al. Deep crossing: Web-scale modeling without manually crafted combinatorial feautures. Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 2016.

### 动机

- 离散类特征编码后过于稀疏，不利于直接输入神经网络进行训练，如何解决稀疏特征向量稠密化的问题。
- 如何解决特征自动交叉组合的问题。
- 如何在输出层中达成问题设定的优化目标。

### 应用场景

该模型的应用场景是微软搜索引擎Bing中的搜索广告推荐场景，用户在搜索引擎中输入搜索词之后，搜索引擎除了会返回相关结果，还会返回与搜索词相关的广告。Deep Crossing模型的优化目标是尽可能地增加搜索广告的点击率，准确地预测广告点击率，并以此作为广告排序的指标之一。

### 输入表示

使用的特征可分为三类：

- 类别型特征：包括用户搜索词（query）、广告关键词（keyword）、广告标题（title）、落地页（landing page）、匹配类型（match type）；
- 数值型特征（计数型特征，couting feature）：包括点击率、预估点击率（click prediction）；
- 需要进一步处理的特征：包括广告计划（campaign）、曝光样例（impression）、点击样例（click），这些特征都不是独立的特征，而是一个特征的组别，需要进一步处理。例如广告计划中的预算作为数值型特征，而广告计划中的id则可以作为类别型特征。

类别型特征可以通过one-hot或multi-hot编码生成特征向量，数值型特征则可以直接拼接进特征向量中，在生成所有输入特征的向量表达后，Deep crossing模型利用该特征向量进行CTR预估。

### 模型

**Embedding层**：Embedding层的作用是将稀疏的类别型特征转换成稠密的Embedding向量。只有Feature#1类别型特征会经过Embedding层，数值型特征不需要经过Embedding层，直接进入了Stacking层。

**Stacking层**：把不同的Embedding特征和数值型特征拼接在一起，形成新的包含全部特征的特征向量，该层通常也被称为连接层（concatenate layer）。

**Multiple Residual Units层**：该层的主要结构是多层感知机，Deep Crossing模型采用了多层残差网络作为MLP的具体实现。通过多层残差网络对特征向量各个维度进行充分的交叉组合，使模型能够抓取到更多的非线性特征和组合特征的信息，进而是深度模型在表达能力上较传统机器学习模型大为增强。

**Scoring层**：作为输出层，为了拟合优化目标而存在。对于CTR预估这种二分类问题，Scoring层往往使用的是逻辑回归模型，对于多分类问题，往往采用softmax模型。

<img src="..\Img\Recommender-System\Recommender-System\02.png" alt="image-20200801192013730" style="zoom: 80%;" />

### 评价

**优点**：

- Deep Crossing模型中没有任何人工特征工程的参与，原始特征经Embedding后输入神经网络层，将全部特征交叉的任务交给模型。

- 相比之前的FM、FFM模型只具备二阶特征交的能力，Deep Crossing模型可以通过调整神经网络的深度进行特征之间的“深度交叉”。



## 4.3 PNN

> Qu, Yanru, et al. Product-based neural networks for user response prediction. 2016 IEEE 16th International Conference on Data Mining(ICDM). IEEE, 2016.

**改进**：

- PNN模型在输入、Embedding层、多层神经网络以及最终的输出层部分并没有结构上的不同，唯一的区别在于PNN模型用Product Layer代替了Deep Crossing模型中的Stacking层。

### 模型

**Embedding层**：不仅包括用户和物品信息，还可以有更多不同形式、不同来源的特征，通过Embedding层的编码生成同样长度的稠密特征Embedding向量。

**Product Layer层**：不同特征的Embedding向量不再是简单的拼接，而是用Product操作进行两两交互，更有针对性地获取特征之间的交叉信息。

- PNN模型的product layer由线性内积操作部分对各特征向量进行线性拼接和乘积外积操作部分组成，其中，无论是内积操作还是外积操作，都是对不同的特征Embedding向量进行两两组合。为了保证内及操作和外积操作能够顺利进行，各Embedding向量的维度必须相同。
- 内积操作即经典的向量内积运算，假设输入的特征向量分别为$f_i$,$f_j$,特征的内积互操作$g_{inner}(f_i,f_j)$的定义如下：

$$
g_{inner}(f_i,f_j)=<f_i,f_j>
$$

​		外积操作是对输入特征向量$f_i$,$f_j$的各维度进行两两交叉，生成特征交叉矩阵，外积互操作$g_{inner}(f_i,f_j)$的定		义如下：
$$
g_{outer}(f_i,f_j)=f_if_j^T
$$
​		(这部分如果用到再深挖)

- 使用内积操作的PNN模型被称为IPNN（Inner Product-based Neural Network），使用外积操作的PNN被称为OPNN（Outer Product-based Neural Network）

<img src="..\Img\Recommender-System\Recommender-System\06.png" alt="image-20200801204239868" style="zoom:50%;" />

### 评价

**优点**：

- PNN结构的特点在于强调特征Embedding向量之间的交叉方式是多样化的，相比于简单的交由全连接层进行无差别的处理，PNN模型定义的内积和外积操作显然更有针对性地强调了不同特征之间的交互，从而让模型更容易捕获特征的交叉信息。

**缺点**:

- 外积操作在实际应用中为了优化训练效率进行了大量的简化操作。
- 对所有特征进行无差别的交叉，在一定程度上忽略了原始特征向量中包含的有价值信息。

## 4.4 NeuralCF

新加披国立大学于2017年提出了基于深度学习的协同过滤模型NeuralCF

> He, Xiangnan, et al. Neural collavorative filtering. Proceedings of the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee, 2017

### 从深度学习的视角看代矩阵分解模型

矩阵分解层的用户隐向量和物品隐向量完全可以看作一种Embedding方法。最终的“Scoring层”就是将用户隐向量和物品隐向量进行内积操作后得到“相似度”，即对评分的预测。

### NeuralCF模型结构

**改进方式1**：

- 用“多层神经网络+输出层”的结构替代了矩阵分解模型中简单的“内积”操作。
  - 一是让用户向量和物品向量做更充分的交叉，得到更多有价值的特征组合信息。
  - 二是引入更多的非线性特征，让模型的表达能力更强。

<img src="..\Img\Recommender-System\Recommender-System\04.png" alt="image-20200801201307013" style="zoom: 50%;" />

### NeuralCF混合模型结构

**改进方式二**：

- 用户和物品向量的互操作层可以被任意的互操作形式所代替，所谓的“广义矩阵分解”模型（Generalized Matrix Factorization，GMF）。比如“元素积”(element-wise product,长度相同的两个向量的对应维相乘得到另一向量)的方式进行互操作。

<img src="..\Img\Recommender-System\Recommender-System\05.png" alt="image-20200801202608480" style="zoom:50%;" />

### 评价

**优点**：

- Neural模型实际上提出了一个模型框架，它基于用户向量和物品向量这两个Embedding层，利用不同的互操作层进行特征的交叉组合，并且可以灵活地进行不同互操作层的拼接。
- 利用深度学习构建推荐模型的优势：利用神经网络理论上能够拟合任意函数的能力，灵活地组合不同的特征，按需增加或减少模型的复杂度。

**缺点**：

- 基于协同过滤的思想进行构造，没有引入更多其他类型的特征，在实际应用中浪费了其他有价值的信息。



## 4.5 Wide&Deep

谷歌应用商店推荐团队于2016年提出。

> cheng，Heng-Tez，et al. Wide & Deep learning for recommender system. Proceedings of the 1st workshop on deep learning for recommender systems. ACM, 2016

### 应用场景

APP推荐场景

### 基本思想

Wide&Deep模型是由单层的Wide部分和多层的Deep部分组成的混合模型。

- Wide部分的主要作用是让模型具有较强的“记忆能力”，可以理解为模型直接学习并利用历史数据中物品或者特征的“共现频率”的能力。一般来说，协同过滤、逻辑回归等简单模型有较强的“记忆能力”。由于这类模型的结构简单，原始数据往往可以直接影响推荐结果，产生类似“如果点击过A，就推荐B”这类规则式的推荐，这就相当于模型直接记住了历史数据的分布特点，并利用这些记忆进行推荐。（wide部分本质为组合特征的线性表示）
  - 像逻辑回归发现“强特征”（对于推荐效果作用大的特征），则其响应的权重就会在模型训练过程中被调整得非常大，这样就实现了对这个特征的直接记忆。
  - 对于多层神经网络来说，特征会被多层处理，不断与其他特征进行交叉，因此模型对这个强特征的记忆反而没有简单模型深刻。
- Deep部分的主要作用是让模型具有“泛化能力”：可以理解为模型传递特征的相关性，以及发掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力。
  - 矩阵分解比协同过滤的泛化能力强，因为矩阵分解引入了隐向量这样的结构，使得数据稀少的用户或者物品也能生成隐向量，从而获得有数据支撑的推荐得分，这就是非常典型的将全局数据传递到稀疏物品上，从而提高泛化能力的例子。
  - 深度神经网络通过特征的多次自动组合，可以深度发掘数据中潜在的模式，即使是非常稀疏的特征向量输入，也能得到较稳定平滑的推荐概率，这就是简单模型所缺乏的“泛化能力”。

### 模型结构

Wide&Deep模型把单输入层的Wide部分与由Embedding层和多隐层组成的Deep部分连接起来，一起输入最种的输出层。

- 单层的Wide部分善于处理大量稀疏的id类特征；
- Deep部分利用神经网络表达能力强的特点，进行深层的特征交叉，挖掘藏在特征背后的数据模式。

![image-20200801214612749](..\Img\Recommender-System\Recommender-System\07.png)

**输入层**

- Wide部分的输入仅仅是已安装应用和曝光应用两类特征，其中已安装应用代表用户的历史行为，而曝光应用代表当前的待推荐应用。
  - 选择这两类特征的原因是充分发挥Wide部分“记忆能力”强的优势。
- Deep部分的输入是全量的特征向量，包括用户年龄（age）、已安装应用数量（#App Installs）、设备类型(Device Class)、已安装应用（User Installed App）、曝光应用（Impression App）等特征。这些特征需要经过embedding向量，再依次经过3层ReLU全连接层，最终输入LogLoss输出层。

<img src="..\Img\Recommender-System\Recommender-System\08.png" alt="image-20200801214916452" style="zoom: 80%;" />

**Deep**

3层MLP，如图。

**Wide**

所用函数被称为交叉积变换（Cross Product Transformation）函数，其形式化定义为
$$
\Phi_K(X)=\sum_{i=1}^dx_i^{c_{ki}}\qquad c_{ki}\in\{0,1\}
$$
$c_{ki}$是一个布尔变量，当第i个特征属于第k个组合特征时，$c_{ki}$的值为1，否则为0；$x_i$是第i个特征的值。

在通过交叉积变换层操作完成特征组合之后，Wide部分将组合特征输入最终的LogLoss输出层，与Deep部分的输出一同参与最后的目标拟合，完成Wide与Deep部分的融合。

## 4.6 Deep&Cross（DCN）

> 斯坦福大学与谷歌的研究人员于2017年提出
>
> Wang, Ruoxi, et al. Deep & cross network for ad click predictions. Proceedings of the ADKDD'17. ACM, 2017

### 改进

使用Cross网络替代原来的Wide部分。

设计Cross网路的目的是增加特征之间的交互力度，使用多层交叉层（Cross layer）对输入向量进行特征交叉。（本质上是一个多层残差结构学习高阶特征表示）

### 模型

<img src="..\Img\Recommender-System\Recommender-System\09.png" alt="image-20200801221038634" style="zoom:80%;" />

**Cross**

假设第l层交叉层的输出向量为$x_l$,那么第l+1层的输出向量如下所示：
$$
\textbf{x}_{l+1}=\textbf{x}_0\textbf{x}_l^T\textbf{W}_l+\textbf{b}_l+\textbf{x}_l
$$
交叉层在增加参数方面比较“克制”，每一层仅增加了一个n维的权重向量$w_l$（n维输入向量维度），并且每一层均保留了输入向量，因此输出与输入之间的变化不会特别明显。

### 评价

相较于wide&deep而言，由多层交叉层组成的Cross网络避免了更多基于业务理解的人工特征组合。

## 4.7 FNN

> FNN由伦敦大学学院的研究人员于2016年提出。
>
> zhang, Weinan, Tianming Du, and Jun Wang. Deep learning over multi-field categorical data. European conference on information retrieval. Springer, Cham, 2016

### 贡献

用FM隐向量完成Embedding层初始化

### 动机

在神经网络的参数初始化过程中，往往采用随机初始化这种不包含任何先验信息的初始化方法。由于Embedding层的输入极端稀疏化，导致Embedding层的收敛速度非常缓慢。再加上Embedding层的参数数量往往占整个神经网络参数数量的大半以上，因此模型的收敛速度往往受限于Embedding层。

### 改进

用FM模型训练好的各特征隐向量初始化Embedding层的参数，相当于在初始化神经网络参数时，已经引入了有价值的先验信息。即神经网络训练的起点更接近目标最优点，自然加速了整个神经网络的收敛过程。

### FM的数学形式

$$
y_{FM}(x):=sigmoid(w_0+\sum_{i=1}^N w_ix_i+\sum_{i=1}^{N}\sum_{j=i+1}^N<v_i,v_j>x_ix_j)
$$

其中的参数主要包括常数偏置$w_0$，一阶参数部分$w_i$和二阶隐向量部分$v_i$。

### 模型

<img src="..\Img\Recommender-System\Recommender-System\10.png" alt="img" style="zoom: 50%;" />

x是输入的特征，它是大规模离散稀疏的。可以分为N个Field，每一个Field中，只有一个值为1，其余为0（即one-hot）。Field可以表示为$x[start_i:end_i]$，$W_0^i$为Field i的embedding矩阵。$z_i$为Field i经过embedding后的向量，它由一次项$w_i$、二次项$v_i=(v_i^1,v_i^2,...,v_i^K)$组成，其中K是FM中二次项的向量的维度。$l_1$,$l_2$则为神经网络的全连接层表示。

特别注意：FM初始化Embedding层的具体含义是初始化Embedding神经元与输入神经元之间的连接权重。假设FM隐向量的维度为m，第i个特征域的第k维特征的隐向量是$v_{i,k}=(v_{i,k}^1,v_{i,k}^2,...,v_{i,k}^l,...,v_{i,k}^m)$，那么隐向量的第l维$v_{i,k}^l$就会成为连接输入神经元k和Embedding神经元l之间连接权重的初始值。

需要说明的是，在训练FM的的过程中，并没有对特征域进行区分，但在FNN模型中，特征被分成了不同特征域，因此每个特征域具有对应的Embedding层，并且每个特征域Embedding的维度都应与FM隐向量维度保持一致。

### 评价

**优点**

- 每个特征的嵌入向量是预先采用FM模型训练的，因此在学习DNN模型时，训练开销降低，模型能够更快达到收敛。

**缺点**

- Embedding 的参数受 FM 的影响，不一定准确。
- 预训练阶段增加了计算复杂度，训练效率低。
- FNN 只能学习到高阶的组合特征；模型中没有对低阶特征建模。

### 问题

这里的特征域与FFM的特征域有何不同？具体使用时需要特别注意这个问题。

## 4.8 DeepFM

> 哈尔滨工业大学和华为公司于2017年联合提出
>
> Guo, Huifeng, et al. DeepFM: a factorization-machine based neural network for CTR prediction. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17). 2017.

### 贡献

用FM代替Wide部分。

### 动机

Wide&Deep模型的Wide部分不具备自动的特征组合能力的缺陷。

### 改进

使用FM替换了原来的Wide部分，加强了浅层网络部分特征组合的能力。具体来说，左侧的FM部分对不同的特征域的Embedding进行了两两交叉，也就是将Embedding向量当作原FM中的特征隐向量，最后将FM的输出与Deep部分的输出一同输入最后的输出层，参与最后的目标拟合。

![image-20200802114558646](..\Img\Recommender-System\Recommender-System\11.png)

### 与Deep&Cross对比

DeepFM的改进动机与Deep&Cross模型的完全一致，唯一的不同就在于Deep&Cross模型利用多层Cross网络进行特征组合，而DeepFM模型利用FM进行特征组合。

但具体应用效果需要通过实验进行比较。

## 4.9 NFM

> 新加披国立大学的研究人员于2017年提出
>
> He, Xiangnan, Tat-seng Chua. Neural factorization machines for sparse predictive analytics. Proceedings of the 40th international ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2017.

### 贡献

FM的神经网络化尝试

### 动机

受组合爆炸问题的困扰，FM几乎不可能扩展到三阶以上，这不可避免地限制了FM模型的表达能力。

### 改进

在数学形式上，NFM模型的主要思路是用一个表达能力更强的函数替代原FM中二阶隐向量内积的部分，$f(x)$的构造工作可以交由某个深度学习网络来完成，并通过梯度反向传播来学习。
$$
\hat{y}_{NFM}=w_0+\sum_{i=1}^Nw_ix_i+f(x)
$$

### 模型

<img src="..\Img\Recommender-System\Recommender-System\12.png" alt="image-20200802130154351" style="zoom:50%;" />

NFM的模型架构即在embedding层和多层神经网络之间加入特征交叉池化层(Bi-Interaction Pooling Layer)，假设$V_x$是所有特征域的Embedding集合，那么特征交叉池化层的具体操作如下
$$
f_{BI}(V_x)=\sum_{i=1}^N\sum_{j=i+1}^N(x_iv_i)\odot(x_jv_j)
$$
其中，$\odot$代表两个向量的元素积操作，即两个长度相同的向量对应维相乘得到元素积向量，其中第k维的操作如下所示：
$$
(v_i\odot v_j)_k=v_{ik}v_{jk}
$$
在进行两两Embedding向量的元素积操作后，对交叉特征向量取和，得到池化层的输出向量。再把该向量输入上层的多层全连接层神经网络，进行进一步的交叉。



## 4.10 AFM

> 浙江大学于2017年提出
>
> Xiao, Jun, et al. Attentional factorization machines: Learning the weight of feature interactions via attention networks. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence. 2017

### 贡献

使用注意力机制（weighted-sum pooling）替换加和池化（sum pooling）。

### 动机

在NFM模型中，不同域的特征Embedding向量经过特征池话层的交叉，将各交叉特征向量进行“加和”，输入最后由多层神经网络组成的输出层。问题的关键在于加和池化(sum pooling)操作相当于“一视同仁”地对待所有交叉特征，不考虑不同特征对于结果的影响程度，事实上消解了大量有价值的信息。

### 改进

基于假设“不同的交叉特征对于结果的影响程度不同”，以更直观的业务场景为例，用户对不同交叉特征的关注程度应该是不同的。本质是并不是所有的特征融合是

### 模型

<img src="..\Img\Recommender-System\Recommender-System\13.png" alt="image-20200802132744130" style="zoom: 67%;" />

除了注意力网络部分，其他部分和NFM保持一致

**Attention Net**
$$
a_{ij}^{'}=\textbf{h}^TReLU(\textbf{W}(\textbf{v}_i\odot \textbf{v}_j)x_ix_j+\textbf{b})
$$

$$
a_{ij}=\frac{exp(a_{ij}^{'})}{\sum_{(i,j)\in R_x}exp(a_{ij}^{'})}
$$

其中，要学习的模型参数是特征交叉层到注意力网络全连接层的权重矩阵$\textbf{W}$，偏置向量$\textbf{b}$，以及全连接层到softmax输出层的权重向量$\textbf{h}$。注意力网络与整个模型一起参与梯度反向传播的学习过程。

## 4.11 DIN

> 阿里巴巴于2018年提出
>
> Zhou, Guorui, et al. Deep interest network for click-through rate prediction. Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2018.

### 贡献

基于业务场景的特征之间的相关性引入注意力机制。

### 应用场景

电商广告推荐。在计算一个用户u是否点击一个广告a时，模型的输入特征自然分为两大部分：

- 用户u的特征组
- 候选广告a的特征组

在这两组特征中都含有两个非常重要的特征——商品id(good_id)和商铺id(shop_id)。

- 用户特征里的商品id是一个序列，代表用户曾经点击过的商品集合；商铺id同理。
- 广告特征里的商品id和商铺id就是广告对应的商品id和商铺id（阿里巴巴平台上的广告大部分是参与推广计划的商品）。

### 动机

在原来的基础模型（Base模型）中，用户特征组中的商品序列和商铺序列经过简单的平均池化操作后就进入上层神经网络进行下一步训练，序列中的商品既没有区分重要程度，也和广告特征中的商品id没有关系。

### 改进

广告特征和用户特征的关联程度是非常强的，从模型的角度来说，在建模过程中投给不同特征的“注意力”理应有所不同，而且“注意力得分”的计算理应与广告特征有相关性。

利用候选商品和历史行为商品之间的相关性计算出一个权重，这个权重就代表了“注意力”的强弱。

### 模型

<img src="..\Img\Recommender-System\Recommender-System\14.png" alt="image-20200802143827849" style="zoom: 67%;" />

注意力部分的形式化表达如下：
$$
\textbf{V}_u=f(\textbf{V}_a)=\sum_{i=1}^Nw_i\textbf{V}_i=\sum_{i=1}^Ng(\textbf{V}_i,\textbf{V}_a)·\textbf{V}_i
$$
其中，$V_u$是用户的Embedding向量，$V_a$是候选广告商品的Embedding向量，$V_i$是用户u的第i次行为的Embedding向量。

$g(\textbf{V}_i,\textbf{V}_a)$函数是使用一个注意力激活单元来生成注意力得分。这个注意力激活单元本质上也是一个小的神经网络。

- 激活单元的输入层是两个Embedding向量，经过元素减(element-wise minus)操作后，与原Embedding向量以同连接后形成全连接层的输入，最后通过单神经元输出层生成注意力得分。

注意：商铺id只跟用户历史行为中的商铺id序列发生作用，商品id只跟用户的商品id序列发生作用，因为注意力的轻重更应该由同类信息的相关性决定。

## 4.12 DIEN

> 阿里巴巴于2019年提出DIN的演化版本DIEN。
>
> Zhou, Guorui, et al. Deep interest evolution network for click-through rate prediction. Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. 2019.

### 贡献

用序列模型模拟了用户兴趣的进化过程。

### 应用场景

电商广告推荐

### 动机

无论是电商购买行为，还是视频网站的观看行为，或是新闻应用的阅读行为，特定用户的历史行为都是一个随时间排序的序列，这样的序列信息对于推荐过程无疑是有价值的。

- 加强了最近行为对下次行为预测的影响。
- 序列模型能够学习到购买趋势的信息。

如果放弃序列信息，则模型学习时间和趋势这类信息的能力就不会那么强，推荐模型就仍然是基于用户所有购买力是的综合推荐，而不是针对“下一次购买”推荐。而且从业务的角度看，后者才是推荐系统正确的推荐目标。

### 改进

使用GRU建模序列信息

### 模型

<img src="..\Img\Recommender-System\Recommender-System\15.png" alt="image-20200802151104600" style="zoom:67%;" />

模型的整体架构仍然为“输入层+Embedding层+连接层+多层全连接神经网络+输出层”

关键在于如何构建“兴趣进化网络”。

- 行为序列层：主要作用是把原始的id类行为序列转换成Embedding行为序列。（与普通的Embedding层是一致的）
- 兴趣抽取层：主要作用是通过模拟用户兴趣迁移过程，抽取用户兴趣。
- 兴趣进化层：主要作用是通过在兴趣抽取层基础上加入注意力机制，模拟与当前目标广告相关的兴趣进化过程。

**兴趣抽取层**

基本结构是GRU网络。与LSTM相比，GRU参数数量更少，训练收敛速度更快。

**兴趣进化层**

DIEN在模拟兴趣进化的过程中，需要考虑与目标广告的相关性。

兴趣进化层完成注意力机制的引入是通过AUGRU（GRU with Attentional Update gate，基于注意力更新门的GRU）结构，AUGRU在原GRU的更新门的结构上加入了注意力得分。
$$
\tilde{u}_t^{'}=a_t \cdot u_t^{'}
$$

$$
h_t^{'}=(1-\tilde{u}_t^{'})\circ h^{'}_{t-1}+\tilde{u}^{'}_t\circ \tilde{h}^{'}_t
$$

**缺点**：

- 序列模型需要比较高的训练复杂度
- 线上推断过程中串行推断，使其模型服务过程中延迟较大，无疑增大了其上线的难度，需要在工程上着重优化。

## 4.13 DRN

> 宾夕法尼亚州立大学和微软亚洲研究院的学者于2018年提出的推荐领域强化学习。
>
> Zheng, Guanjie, et al. DRN: A deep reinforcement learning framework for news Recommender. Proceedings of the 2018 World Wide Web Conference. International World Wide Web Conference Steering Committee, 2018.

### 贡献

将强化学习的理念引入推荐系统。

### 动机

强化学习起源于机器人领域，针对智能体(Agent)在不断变化的环境(Environment)中决策和学习的过程进行建模。在智能体的学习过程中，会完成收集外部反馈(Reward)，改变自身状态(State)，再根据自身状态对下一步的行动(Action)进行决策，在行动之后持续收集反馈的循环，简称“行动-反馈-状态更新”的循环。

可以尝试把推荐系统也当作一个智能体，把整个推荐系统学习更新的过程当作智能体“行动-反馈-状态更新”的循环。

### 深度强化学习推荐系统框架

<img src="..\Img\Recommender-System\Recommender-System\16.png" alt="image-20200802164218157" style="zoom:67%;" />

智能体(Agent)：推荐系统本身，它包括基于深度学习的推荐模型、探索（explore）策略，以及相关的数据存储(memory)。

环境(Environment)：由新闻网站或APP、用户组成的整个推荐系统外部环境。在环境中，用户接受推荐的结果并作出相应反馈。

行动(Action)：对一个新闻推荐系统来说，“行动”指的就是推荐系统进行新闻排序后推送给用户的动作。

反馈(Reward)：用户收到推荐结果后，进行正向的或负向的反馈。

- 例如，点击行为被认为是一个典型的正反馈，曝光未点击则是负反馈的信号。
- 用户的活跃程度，用户打开应用的间隔时间也被认为是有价值的反馈信号。

状态(State)：状态值的是对环境及自身当前所处具体情况的刻画。

- 在新闻推荐场景中，状态可以被看作已收到所有行动和反馈，以及用户和新闻的所有相关信息的特征向量表示。
- 站在传统机器学习的角度，“状态”可以被看作已收到的、可用于训练的所有数据的集合。

在这样的强化学习框架下，模型的学习过程可以不断地迭代，迭代过程主要有以下几步：

（1）初始化推荐系统(智能体)；

（2）推荐系统基于当前已收集的数据(状态)进行新闻排序（行动），并推送到网站或APP（环境）中。

（3）用户收到推荐列表，点击或者忽略（反馈）某推荐结果。

（4）推荐系统收到反馈，更新当前状态或通过模型训练更新模型。

（5）重复第2步。

### 深度强化学习推荐模型

在DRN框架中，使用Deep Quality Network(DQN)算法，来通过对行动进行质量评估，得到行动的效用得分，以此进行行动决策。（即强化学习中的Deep Q-Learning算法，只不过用来估计Q的神经网络是常用推荐算法神经网络结构）

<img src="..\Img\Recommender-System\Recommender-System\17.png" alt="image-20200802170045457" style="zoom:50%;" />

**输入**

在特征工程中套用强化学习状态向量和行动向量的概念

- 状态向量（State）：用户特征（user feature）和环境特征（context features），因为这些特征与具体的行动无关。
- 行动特征（Action）：用户-新闻交叉特征和新闻特征，因为这些特征与推荐新闻这一行动相关。

**过程**

用户特征和环境特征经过左侧多层神经网络的拟合生成价值（Value）得分$V(\textbf{s})$，利用状态向量和行动向量生成优势(advantage)得分$A(\textbf{s},\textbf{a})$，最后把两部分得分综合起来，得到最终的质量得分$Q(\textbf{s},\textbf{a})$。

### 学习过程

<img src="..\Img\Recommender-System\Recommender-System\18.png" alt="image-20200802170819537" style="zoom: 67%;" />

按照从左至右的时间顺序，大致过程为：

（1）在离线部分，根绝历史数据训练好DQN模型，作为智能体的初始化模型。

（2）在$t_1->t_2$阶段，利用初始化模型进行一段时间的推送服务，积累反馈（feedback）数据。

（3）在$t_2$时间点，利用$t_1->t_2$阶段积累的用户点击数据，进行模型微更新(minor update)。

（4）在$t_4$时间点，利用$t_1->t_4$阶段的用户点击数据及用户活跃度数据进行模型的主更新(major update)。

（5）重复第2~4步。

### 竞争梯度下降算法——微更新在线学习方法

<img src="..\Img\Recommender-System\Recommender-System\19.png" alt="image-20200802171333560" style="zoom:50%;" />

竞争梯度下降的主要步骤为：

（1）对于已经训练好的当前网络Q，对其模型参数W添加一个较小的随机扰动$\Delta \textbf{W}$，得到新的模型参数$\tilde{\textbf{W}}$，这里称$\tilde{\textbf{W}}$对应的网络为探索网络$\tilde{Q}$。
$$
\Delta \textbf{W}=\alpha\cdot rand(-1,1)\cdot\textbf{W}
$$
其中，$\alpha$是探索因子，决定探索力度的大小。$rand(-1,1)$是一个[-1,1]之间的随机数。

（2）对于当前网络Q和探索网络$\tilde{Q}$，分别生成推荐列表L和$\tilde{L}$，用Interleaving将两个推荐列表组合成一个推荐列表后推送给用户。

（3）实时收集用户反馈。如果探索网络$\tilde{Q}$生成内容的效果好于当前网络Q，则用探索网络代替当前网络，进入下一轮迭代；反之则保留当前网络。

**评价**：DRN的在线学习过程利用“探索”的思想，其调整模型的粒度可以精细到每次获得反馈之后，这一点很像随机梯度下降的思路，虽然一次样本的结果可能产生随机扰动，但只要总的下降趋势是正确的，就能通过海量的尝试最终达到最优点。

### 评价

强化学习的优势在于强化学习模型能够进行“在线学习”，不断利用新学到的知识更新自己，及时做出调整和反馈。



# 5. 召回层主要策略

## 5.1 召回层与排序层对比

|        | 特点                                   | 功能                                                         |
| ------ | -------------------------------------- | ------------------------------------------------------------ |
| 召回层 | 数据量大、速度快、模型简单、特征较少   | 利用少量的特征合简单的模型或规则进行候选集的快速筛选，减少精准排序阶段的时间开销。 |
| 排序层 | 数据量小、排序精准、复杂模型、特征较多 | 精准排序                                                     |

## 5.2 策略

### 概述

- 时间召回(召回最近n天内容，保证内容时效性，一般不单独设置召回桶，而是在内容库阈值中设置过期时间体现)
- 热销召回(召回最近n天内曝光量超过x并且点击率(CTR 文章的点击量/曝光量)较高的内容)
- 标签召回(根据用户最近的点击内容标签来召回相同标签内容)
- 协同召回(根据用户最近的点击内容来召回相似文章，而协同又分两种方式：根据物品的协同/根据用户的协同)
- 关注召回(根据用户关注的作者/专栏等召回可能感兴趣内容)
- 特殊召回：
  - 英雄召回(根据用户最近玩过的英雄/模式等召回用户最近感兴趣的内容)
  - 优选池召回：针对部分运营认为不错的文章来做强曝光处理；
  - 视频池召回：同上
  - 指定作者召回：同上
  - 赛事召回

### 多路召回策略

多路召回策略指采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用的策略。

**例如**

对于信息流应用，常用包括”热门新闻“（一些预处理好的召回策略）、”兴趣标签“（基于单一特征召回方法）、”协同过滤“（计算效率高的简单模型）、”最近流行“、”朋友喜欢“等

对于视频推荐来说，常用包括”热门视频“、”导演召回“、”演员召回“、”最近上映“、”流行趋势“、”类型召回“等。

**方法**

每一路召回策略会拉取K个候选物品，对于不同的召回策略，K值可以选择不同的大小。

这里K值是超参数，一般需要通过离线评估加线上A/B测试的方式确定合理的取值范围。

**评价**

优点：多路召回策略是在”计算速度“和”召回率“之间进行权衡的结果。

缺点：多路召回策略从策略选择到候选集大小参数的调整都需要人工参与，策略之间的信息也是割裂的，无法综合考虑不同策略对一个物品的影响。

### 基于Embedding的召回方法

(todo，需要积累新知识，整理积累中)

**评价**

**优点**：

- 在效果和速度上均不逊色于多路召回。多路召回中使用”兴趣标签“、”热门度“、”流行趋势“、”物品属性“等信息都可以作为Embedding找回方法中的附加信息融合进最终的Embedding向量中，就相当于在利用Embedding召回的过程中，考虑到了多路召回的多种策略。
- 评分的连续性。多路召回中不同召回策略吵闹声的相似度、热度等分值不具备可比性，无法据此决定每个召回策略放回候选集的大小。Embedding召回可以把Embedding间的相似度作为唯一的判断标准，因此可以随意限定召回的候选集大小。



# 6. 实时性

## 6.1 重要性

从用户的角度：

显然成立

从机器学习的角度：

（1）推荐系统的更新速度越快，代表用户最近习惯和爱好的特征更新越快，更能为用户进行更有实效性的推荐。

（2）推荐系统更新得越快，模型越容易发现最新流行得数据模式，越能让模型快速抓取最新得流行趋势。

## 6.2 特征的实时性

推荐系统特征的实时性指的是”实时“地收集和更新推荐模型的输入特征，使推荐系统总能使用最新的特征进行预测和推荐。

根据推荐系统的数据流，说明可能影响特征“实时性”的三个主要阶段：

- 客户端实时特征：
  - 过往做法：由于延迟问题，系统可能无法在短时间之内就把session内部的的行为历史存储到特征数据库(如，Redis)中，这就导致用户的推荐结果不会马上受到session内部行为的影响，无法做到推荐结果的实时更新。
  - 如果客户端能够缓存session内部的行为，将其作为与上下文特征同样的实时特征传给推荐服务器，那么推荐模型就能够**实时地**得到session内部地行为特征，进行实时的推荐。
- 流计算平台的准实时特征处理：
  - 流计算平台是将日志以流的形式进行维批处理(mini batch)，如Storm，Spark Streaming、Flink
  - 利用流计算平台进行准实时的特征处理，每次需要等待并处理一小批日志，流计算平台并非完全实时的平台。优势是能够进行一些简单的统计类特征的计算。
  - 流计算平台计算出的特征可以立刻存入特征数据库供推荐模型使用。虽然无法实时地根据用户行为改变用户结果，但**分钟级别**的延迟基本可以保证推荐系统能够**准实时地**引入用户的近期行为。
- 分布式批处理平台的全量特征处理
  - 用户的曝光、点击、转换数据往往是在不同时间到达的HDFS，有些游戏类应用的转换数据延迟甚至高达几个小时，因此只能在全量数据批处理这一阶段才能进行全部特征及相应标签的抽取和合并，这往往是无法在客户端和流计算平台上计算的。
  - 主要用途：模型训练和离线评估；特征保存入特征数据库，共之后的线上推荐模型使用。
  - 数据从产生到完全进入HDFS，再加上Spark的计算延迟，这一过程的总延迟往往达到小时级别，已经**无法进行所谓的“实时”推荐**，因此更多的是保证推荐系统特征的全面性，以便在用户下次登录时进行更准确的推荐。

## 6.3 模型的实时性

模型的实时性是与模型的训练方式紧密相关的，模型的实时性由弱到强的训练方式分别是**全量更新**、**增量更新**和**在线学习**。

### 全量更新

全量更新是指模型利用某时间段内的所有训练样本进行训练。

**特点**：全量更新需要所有训练数据都记录在HDFS等大数据存储系统中才可以进行，

**缺点**：训练全量样本的时间往往较长。

### 增量更新

增量更新是仅将新加入的样本“喂”给模型进行增量训练。

**特点**：相当于在原有样本的基础上继续输入增量样本进行梯度下降。

**缺点**：增量更新的模型往往无法找到全局最优点。

**使用建议**：实践中，经常采用增量更新与全局更新相结合的方式，在进行了几轮增量更新后，在业务量较小的时间窗口进行全局更新，纠正模型在增量更新中积累的误差。

### 在线学习

在线学习即在获得一个新的样本的同时更新模型。

**缺点**：

- 需要在线上环境进行模型的训练和大量模型相关参数的更新和存储。
- 模型的稀疏性不强。例如，在一个输入特征向量达到几百万维的模型中，如果模型的稀疏性好，就可以在模型效果不受影响的前提下，仅让极小一部分特征对应的权重非零，从而让上线的模型体积很小（因此可以摒弃所有权重为0的特征），这有利于加快整个模型服务的过程。但如果使用SGD的方式进行模型更新，相比batch的方式，容易产生大量小权重的特征，这就增大了模型的体积，从而增大模型部署和更新的难度。

### 局部更新

局部更新的大致思路是降低训练效率低的部分的更细你频率，提高训练效率高的部分的更新频率。

例如，在“Embedding层+神经网络”的深度学习模型中，Embedding层参数由于占据了深度学习模型参数的大部分，其训练过程会拖慢模型整体的收敛速度，因此业界往往采用Embedding层单独预训练，Embedding层以上的模型部分高频更新的混合策略。

### 客户端模型实时更新

对于推荐模型这类“重量级”的模型，往往需要依赖服务器端较强大的计算资源和丰富的特征数据进行模型服务。但客户端往往可以保存和更新模型一部分的参数和特征，比如当前用户的Embedding向量。



# 7. 优化目标

(todo，需要学习新知识，积累整理中)

对一家商业公司而言，在对大多数情况下，推荐系统的目标都是完成某个商业目标，所以根据公司的商业目标来制定推荐系统的优化目标理应作为“合理”的战略性目标。

视频推荐举例：

如果以点击率为优化目标，那么推荐系统会倾向于推荐“标题党”“预览图劲爆”的短视频，

如果以播放时长为优化目标，那么推荐系统应该将视频的长度、视频的质量等特征考虑进来，此时推荐一个高质量的“电影”或“连续剧”就是更好的选择。

# 8. 评估

## 8.1 离线测试

一般的准确率、均方差、对数损失都更多地将推荐模型视作类似于点击率预估地预测模型，而不是一个排序模型。其中存在的弊端是：预测模型的要求预测概率应具有物理意义，即预测出的点击率应该接近经验点击率。

事实上，推荐系统的最终结果是一个排序列表，使用诸如**P-R曲线、ROC曲线、平均精度均值**更有意义。

除了这是三个常用指标，还包括归一化累计收益(Normalized Discounted Cumulative Gain, NDCG)、覆盖率、多样性等。

注意：离线评估的目的在于快速定位问题，快速排除不可行的思路，为线上评估找到“靠谱”的候选者，根据业务场景选择2~4个有代表性的离线指标，进行高效率的离线实验才是离线评估正确的“打开方式”。

#### Replay

**动态离线评估**：先根据样本产生时间对测试样本由早到晚进行排序，再用模型根据样本时间依次进行预测。在模型更新的时间点上，模型需要增量学习更新时间点前的测试样本，更新后续继续进行后续的评估。

如果模型更新的频率持续加快，快到接收到样本后就更新，整个动态评估的过程编程逐一样本回放的精准线上仿真过程，这就是仿真式离线评估方法——replay。

## 8.2 interleaving

Interleaving：不区分A/B组，而是把不同的被测对象同时提供给受试者，最后根据受试者的喜好得出评估结果的方法。

**评价**：

优点：

- 所需样本少（灵敏度更高）、测试速度快，结果于传统的A/B测试无明显差异（具有一定的相关性）

局限性：

- 工程实现的框架较传统A/B测试复杂。Interleaving的实验逻辑和业务逻辑纠缠在一起，因此业务逻辑可能会被干扰；为了实现Interleaving方法，需要将大量辅助性的数据标识添加到整个数据流中。
- Interleaving方法只是对“用户对算法推荐结果偏好程度”的相对测量，不能得出一个算法的真实表现。需结合A/B test构建两阶段实验结构来完善整个流程。

## 8.3 A/B测试

### 概述

A/B测试又称为“分流测试”或"分桶测试"，是一个随机实验，通常分为实验组和对照组。在利用控制变量法保持单一变量的前提下，将A、B两组数据进行对比，得出实验结论。

在互联网场景下的算法测试中，可将用户随机分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型，比较实验组和对照组在各线上评估指标上的差异。

### 分桶原则

在A/B测试分桶的过程中，需要注意的时样本的独立性和采样方式的无偏性：

- 同一个用户在测试的全程只能被分到同一个桶中，在分桶过程中所用的用户ID应是一个随机数，这样才能保证同种的样本是无偏的。

### 分层和分流的机制

**现实**：在实际的A/B测试场景中，同一个网站或应用往往要同时进行多组不同类型的A/B测试，例如在前端进行不同APP界面的A/B测试，在业务层进行不同中间效率的A/B测试，在算法层同时进行推荐场景1和推荐场景2的A/B测试。

**原则**：

- 层与层之间的流量“正交”：即层与层之间的独立实验的流量是正交的，即实验中的每组流量穿越该层后，都会被再次随机打散，且均匀地分布在下层实验的每个实验组中。
- 同层之间的流量“互斥”
  - 如果同层之间进行多组A/B测试，那么不同测试之间的流量是不重叠的，即“互斥”的。
  - 一组A/B测试中的实验组和对照组的流量是不重叠的，是“互斥”的。

**评估指标**

A/B测试的指标应与线上业务的核心指标保持一致。

| 推荐系统类别 | 线上A/B测试评估指标                                       |
| ------------ | --------------------------------------------------------- |
| 电商类推荐   | 点击率、转化率、客单价（用户平均消费金额）                |
| 新闻类推荐   | 留存率、平均停留时长、平均点击个数                        |
| 视频类推荐   | 播放完成率（播放时长/视频时长）、平均播放时长、播放总时长 |

**注意**：

- 离线评估不具备直接计算业务核心指标的条件，因此选择了偏向于技术评估的模型相关指标。
- 但在公司层面，更关心能够驱动业务发展的核心指标。

下图是一个简单的AB测试系统。用户进入网站后，流量分配系统决定用户是否需要被进行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。然后用户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如果用户有测试分组的标签，那么该标签也会被发回后台数据库。在后台，实验人员的工作首先是配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。

![](..\Img\Recommender-System\Recommender-System\20.png)

当完成了AB测试后，根据指标结果，如果优于之前的推荐算法，那么旧的算法就可以替换成新的了。

### 商业类指标

#### PV点击率

pv点击率衡量整个推荐系统的分发效率，推荐给用户的内容，有多少内容是用户感兴趣并点击的。
$$
pv_{点击率}=\frac{总点击数}{总曝光数}
$$
一般情况下点击数是确定的，曝光数会受到产品的上报策略的影响，比如有些产品会要求曝光3秒以上才上报，用户上下拉产生的 重复曝光有些产品会过滤有些不会，这些需要在前期都沟通好，避免因为统计方法不一致导致数据的差异

一般情况下点击数是确定的，曝光数会受到产品的上报策略的影响，比如有些产品会要求曝光3秒以上才上报，用户上下拉产生的 重复曝光有些产品会过滤有些不会，这些需要在前期都沟通好，避免因为统计方法不一致导致数据的差异

#### UV点击率

UV点击率衡量推荐系统对用户适应性的广度，是否对所有的用户都比较友好。
$$
UV_{点击率}=\frac{有点击用户数}{总曝光用户数}
$$

#### 停留时长

停留时长衡量推荐系统推荐的内容质量的好坏，能否在吸引用户点击的同时给用户好的内容，而不是标题党等

$$
曝光人均停留时长=\frac{每个人的停留时长之和}{曝光用户数} 
$$

$$
点击人均停留时长=\frac{点击用户的停留时长之和}{点击用户数}
$$

需要注意的是停留时长一般包含列表页的停留时长和详情页的停留时长之和

#### 留存率

留存率指标也在一定程度上反映推荐系统内容对用户的吸引度和黏性，一般考虑次留和7留 
$$
次留=\frac{当天曝光用户在第二天还曝光用户数}{当天曝光用户数}
$$

$$
7留=\frac{当天曝光用户在第七天还曝光的用户数}{当天曝光用户数}
$$



## 8.4  其它评估方法

推荐算法其他评估常见的指标包括覆盖度 、多样性、新颖性和惊喜度等。

- 覆盖率：描述一个推荐系统对物品长尾的发掘能力。覆盖率有很多定义方法，最简单的计算就是推荐列表中的物品数量，除以所有的物品数量。 在信息论和经济学中有两个著名的指标用来定义覆盖率，一个是信息熵，一个是基尼系数。
- 多样性：用户的兴趣是多样的，推荐系统需要能覆盖用户各种方面的喜好。这里有个假设，如果推荐列表比较多样，覆盖了用户各种各样的兴趣， 那么真实命中用户的兴趣概率也会越大，那么就会增加用户找到自己感兴趣的物品的概率。
- 新颖性：新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。要准确地统计新颖性需要做用户调查
- 惊喜度：如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高， 而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果。

在线测试一般通过 A/B 测试进行，常见的指标有点击率、用户停留时间、 广告收入等，需要注意分析统计显著性。同时，需要注意短期的指标和长期的指标相结合， 一些短期指标的提升有时候反而会导致长期指标下降 比如 ，经常推荐美女或者搞笑类的内容会带来短期的点击率提高，但是可能会引起长期的用户粘性下降。设计者需要从自己的产品角度出发，根据产品的需要制定评估指标，这样才能更好地指导推荐系统的优化方向。常见的评价指标如下：

![](..\Img\Recommender-System\Recommender-System\23.png)



# 9. 冷启动问题

冷启动（ cold start ）在推荐系统中表示该系统积累数据量过少，无法给新用户作个性化推荐的问题，这是产品推荐的一大难题。每个有推荐功能的产品都会遇到冷启动的问题。一方面，当新商品时上架会遇到冷启动的问题，没有收集到任何一个用户对其浏览、点击或者购买的行为，也无从判断如何将商品进行推荐；另一方面，新用户到来的时候，如果没有他在应用上的行为数据，也无法预测其兴趣，如果给用户的推荐千篇一律，没有亮点，会使用户在一开始就对产品失去兴趣，从而放弃使用。

根据数据匮乏情况的不同，冷启动问题可以分为以下三类。

- 用户冷启动：新用户注册后，没有历史行为数据时的个性化推荐。
  - 解决方法参考以下：

    1. 利用用户的账号信息。
    2. 利用用户的手机 IMEI 号进行冷启动。
    3. 制造选工页，让用户选择自己感兴趣的点后，即时生成粗粒度的推荐。

- 物品冷启动：系统加入新物品后（新的影片、新的商品等），在该商品还没有交互记录时。
  - 解决方法参考以下：

    1. 利用物品的内容、分类信息。
    2. 利用专家标注的数据。
- 系统冷启动：在推荐系统运行之初，缺乏所有相关历史数据时的推荐。

冷启动策略可归为以下三类：

- 基于规则的冷启动过程

  - “热门排行榜”、“最近流行趋势”、“最高评分”，绝大多数音乐、视频等应用都是采用这类方法作为冷启动的默认规则。
  - 参考专家意见建立一些个性化物品列表，根据用户有限的信息（例如注册时填写的年龄、性别、基于IP推断出地址等信息）做粗粒度的规则推荐。
  - 基于规则的冷启动方法更多依赖的是领域专家对业务的洞察。在制定冷启动规则时，需要充分了解公司的业务特点，充分利用已有数据，才能让冷启动规则合理且高效。

- 丰富冷启动过程中可获得的用户和物品特征

  改进推荐模型达到冷启动目的的方法，在模型中加入更多用户或物品的属性特征，而非历史数据特征，这些属性特征主要包括以下几类：

  - 用户的注册信息：包括基本的人口属性信息（年龄、性别、学历、职业等）和通过IP地址、GPS信息等推断出的地理信息。
  - 第三方DMP(Data Management Platform，数据管理平台)提供的用户信息：这些第三方数据管理平台不仅可以提供基本的人口属性特征，通过与大量应用、网站的数据交换，甚至可以提供脱敏的用户兴趣、收入水平、广告倾向等一系列的高阶特征。
  - 物品的内容特征：包括物品的分类、标签、描述文字等。
  - 引导用户输入的冷启动特征：应用会在用户第一次登录时引导用户输入一些冷启动特征。

- 利用主动学习、迁移学习和“探索与利用”机制（todo）